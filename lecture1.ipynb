{"cells":[{"cell_type":"markdown","metadata":{"id":"Le0CG-IM69YW"},"source":["## 1.Parametric Function\n","함수가 기본적으로 파라미터 θ를 포함하고 있다. 입력을 받으면 함수내 정의된 logic의 연산에 θ를 이용한다.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1Gj6ow44vICV_Ysuwp3R5EWzIUPWpflq1\">"]},{"cell_type":"markdown","metadata":{"id":"FTwAqrRH_z6Q"},"source":["일반적인 함수는 정의된 logic대로 연산결과를 출력하지만, parametric function은 함수가 보유중인 파라미터를 추가적으로 이용한다.  \n","따라서 θ값이 변하면(다르면) 동일한 함수여도 다른 결과를 얻게 된다."]},{"cell_type":"markdown","metadata":{"id":"pcNPP1_yBFaT"},"source":["## 2.Tensor\n","텐서는 일반적으로 다차원 배열이나, 스칼라값도 가질 수 있다. 스칼라, 벡터, 행렬 그리고 그 이상의 고차원 배열들을 담는 그릇이자 하나의 단위가 텐서라고 이해하면 될 듯하다.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1YZ8xi6Cw3n6kVq3ucNb8CDpl_IZ5IfUH\">\n","\n","0차원 텐서에서 두 개의 실수간 덧셈, 곱셈을 기반으로 1차원, 2차원, 3차원 텐서에서의 연산으로 확장이 가능하며 새로운 연산을 정의할 수도 있다."]},{"cell_type":"markdown","metadata":{"id":"jigfZlumCg0K"},"source":["## 3.Dataset\n","통상적으로 한 개의 데이터는 row vector 형태로 다룬다.  \n","그리고 row vector 데이터들이 모여서(쌓여서) 하나의 데이터셋을 구성하게 된다.\n","<img src=\"https://drive.google.com/uc?export=download&id=1RAwlV3Aj-2Q6_vZRMXncKZzFnnGE88L_\">\n","\n","참고로 l<sub>i</sub>는 length of input. 즉 한 개의 데이터(1 row)의 길이를 의미한다."]},{"cell_type":"markdown","metadata":{"id":"OQZ_jAZ8NJn4"},"source":["## 3.Weighted Sum & Affine Transformation\n","<img src=\"https://drive.google.com/uc?export=download&id=1rtP6ZHbIhbKPrzUERmO2q1PAzgW13smW\" width=\"480\" height=\"640\">\n","\n","- weighted sum은 입력값 x에 함수가 보유중인 파라미터 w(weight)를 곱해준다. weight의 기능은 입력값 x가 z값에 얼마만큼의 영향을 주게될지 정해준다.\n","- Affine Transformation은 weighted sum에서 b(bias)라는 파라미터가 추가된 것."]},{"cell_type":"markdown","metadata":{"id":"hvfqmw1EPpRq"},"source":["이번에는 데이터 1개가 아니라 다수의 데이터에 대한 식을 알아보자.\n","<img src=\"https://drive.google.com/uc?export=download&id=174eUsZdhUgA3vUQ8hdALXt8RTxrkp68M\">\n","<img src=\"https://drive.google.com/uc?export=download&id=1UmyX5aEypKLyRby17R9BURhKzepzld9d\">\n","\n","데이터의 수가 늘어나도 함수 자체의 연산은 동일하다.  \n","weight가 하는 역할은 입력값 x<sub>1</sub>, x<sub>2</sub>, x<sub>n</sub> 들 각각이 함수값 z에 미치는 영향력을 지정하는 것이다.\n","\n","이때 중요한 사항은 입력 벡터 x<sub>l<sub>I</sub></sub>의 수와 가중치 벡터 w의 수가 같아야한다는 것이다.  \n","즉, 입력 벡터가 x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub> 이라면, 가중치 벡터의 형태는 w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>가 되는 것이다. bias는 1개만 존재."]},{"cell_type":"markdown","metadata":{"id":"QcuGmvCXTQxT"},"source":["## 4.Activation Function\n","\n","Affine Transformation을 거친 이후에, Activation function을 적용하게 된다.  \n","이는 activation function에 입력된 값이 적용한 활성화 함수의 연산에 따라 결과값이 결정되는 형태다.\n","<img src=\"https://drive.google.com/uc?export=download&id=1xP6YiARnabEQj2xz-rOXOYgPXl3JWBXq\">\n","<img src=\"https://drive.google.com/uc?export=download&id=12Wn0dTJzxkYh1G3Y232E8XaZ2NtKAmXn\">"]},{"cell_type":"markdown","metadata":{"id":"dc_XysmgVFt3"},"source":["## 5.Mini-Batch\n","\n","mini batch는 데이터를 하나의 묶음으로 입력하는 것을 의미한다. 예를 들어 batch-size가 32라면 1개의 데이터 묶음 속에 32개의 데이터가 들어가 있다.  \n","데이터 묶음 속 각각의 데이터가 Affine transform, Activation function을 거치게 되는데 이때 함수들이 가지고 있는 weight, bias는 값이 변하지 않음에 유의할 것.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=10FPGwD4wM-62ziN30kdVB4VaOaxpfs_e\">\n","<img src=\"https://drive.google.com/uc?export=download&id=14sdWrA81UoT3XViGCA9WMbplrf9FdbD6\">"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676521029065,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"WD-QFeq2Zvj5","outputId":"57dd780f-25cb-4dd9-cd1d-f1e8272e6a53"},"outputs":[{"name":"stdout","output_type":"stream","text":["x : (1, 1), [[10.]]\n","W : (1, 1), [[-0.9237079]]\n","B : (1,), [0.]\n","y : (1, 1), [[-9.237079]]\n","y manual : (1, 1), [[-9.237079]]\n"]}],"source":["import tensorflow as tf\n","\n","x = tf.constant([[10.]]) ## vector가 아니라 matrix 형태임에 유의할 것.\n","\n","dense = tf.keras.layers.Dense(units=1, activation=\"linear\") ## affine function\n","\n","y = dense(x) ## output. forward propagation + parameter initialization(x값이 입력되는 시점에 weight, bias가 초기화 된다.)\n","\n","W, B = dense.get_weights()\n","\n","## Manual\n","y_manual = tf.linalg.matmul(x, W) + B\n","\n","## print reuslt\n","print(f\"x : {x.shape}, {x.numpy()}\")\n","print(f\"W : {W.shape}, {W}\")\n","print(f\"B : {B.shape}, {B}\")\n","print(f\"y : {y.shape}, {y.numpy()}\")\n","print(f\"y manual : {y_manual.shape}, {y_manual}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1676521604702,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"P-E1A7roafC6","outputId":"512ff147-2514-456b-c3b9-7238d9bc196b"},"outputs":[{"name":"stdout","output_type":"stream","text":["<keras.initializers.initializers_v2.Constant object at 0x7fc3e0c88430> <keras.initializers.initializers_v2.Constant object at 0x7fc3e0c88970>\n","y. : (1, 1), [[120.]]\n","W : (1, 1), [[10.]]\n","B : (1,), [20.]\n"]}],"source":["w, b = tf.constant(10.), tf.constant(20.)\n","w_init, b_init = tf.keras.initializers.Constant(w), tf.keras.initializers.Constant(b) ## Tensor를 만드는게 아니라 Layer의 parameter를 초기화 시키는 object를 만든 것.\n","print(w_init, b_init)\n","\n","dense = tf.keras.layers.Dense(units=1, \n","                              activation=\"linear\", \n","                              kernel_initializer=w_init, \n","                              bias_initializer=b_init)\n","y = dense(x)\n","W, B = dense.get_weights()\n","\n","print(f\"y. : {y.shape}, {y}\")\n","print(f\"W : {W.shape}, {W}\")\n","print(f\"B : {B.shape}, {B}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1676521952048,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"CDJIUHksdzn5","outputId":"4cd3d41f-ed78-4d1a-9d7d-f25b0c83b0da"},"outputs":[{"name":"stdout","output_type":"stream","text":["x : (1, 10), [[9.788488   6.6079273  2.505139   5.4520903  3.4345126  5.6861877\n","  9.138023   0.79270124 0.40567875 9.378441  ]]\n","W : (10, 1), [[ 0.04207242]\n"," [-0.306368  ]\n"," [ 0.02227515]\n"," [-0.02390814]\n"," [-0.3501303 ]\n"," [ 0.06343085]\n"," [-0.07442868]\n"," [-0.0555805 ]\n"," [-0.16030246]\n"," [ 0.598473  ]]\n","B : (1,), [0.]\n","y : (1, 1), [[2.2944963]]\n","y manual : (1, 1), [[2.2944963]]\n"]}],"source":["x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10) ## 한 개의 row vector data\n","\n","dense = tf.keras.layers.Dense(units=1)\n","y = dense(x)\n","W, B = dense.get_weights()\n","\n","y_manual = tf.linalg.matmul(x, W) + B\n","\n","## print reuslt\n","print(f\"x : {x.shape}, {x.numpy()}\") ## row vector\n","print(f\"W : {W.shape}, {W}\") ## column vector\n","print(f\"B : {B.shape}, {B}\")\n","print(f\"y : {y.shape}, {y.numpy()}\")\n","print(f\"y manual : {y_manual.shape}, {y_manual}\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1676523694497,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"iv1u3gjne6S9","outputId":"10fb3109-334e-4fff-d285-65fee0a5c13c"},"outputs":[{"name":"stdout","output_type":"stream","text":["x : (1, 5), [[ 0.47400722  0.68043196  0.26013425 -0.27689335  1.4365736 ]] \n","\n","Sigmoid : (1, 5), [[0.61633176 0.6638351  0.5646693  0.43121555 0.8079235 ]]\n","Tanh : (1, 5), [[ 0.44143143  0.59180015  0.2544211  -0.27002737  0.89300585]]\n","ReLU : (1, 5), [[0.47400722 0.68043196 0.26013425 0.         1.4365736 ]] \n","\n","Sigmoid manual : (1, 5), [[0.61633176 0.6638351  0.5646693  0.43121555 0.8079235 ]]\n","Tanh manual : (1, 5), [[ 0.44143137  0.59180015  0.25442111 -0.27002743  0.89300585]]\n","ReLU manual : (1, 5), [[0.47400722 0.68043196 0.26013425 0.         1.4365736 ]]\n"]}],"source":["x = tf.random.normal(shape=(1, 5))\n","\n","sigmoid = tf.keras.layers.Activation(\"sigmoid\")\n","tanh = tf.keras.layers.Activation(\"tanh\")\n","relu = tf.keras.layers.Activation(\"relu\")\n","\n","y_sigmoid = sigmoid(x)\n","y_tanh = tanh(x)\n","y_relu = relu(x)\n","\n","print(f\"x : {x.shape}, {x.numpy()} \\n\")\n","print(f\"Sigmoid : {y_sigmoid.shape}, {y_sigmoid.numpy()}\")\n","print(f\"Tanh : {y_tanh.shape}, {y_tanh.numpy()}\")\n","print(f\"ReLU : {y_relu.shape}, {y_relu.numpy()} \\n\")\n","\n","y_sigmoid_man = 1 / (1 + tf.math.exp(-x))\n","y_tanh_man = (tf.exp(x) - tf.exp(-x)) / (tf.exp(x) + tf.exp(-x))\n","y_relu_man = tf.math.maximum(x, 0)\n","\n","print(f\"Sigmoid manual : {y_sigmoid_man.shape}, {y_sigmoid_man.numpy()}\")\n","print(f\"Tanh manual : {y_tanh_man.shape}, {y_tanh_man.numpy()}\")\n","print(f\"ReLU manual : {y_relu_man.shape}, {y_relu_man.numpy()}\")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1676524172688,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"08iyFswxifp-","outputId":"4b2ddee9-b65d-4fea-ed0e-1d967a721c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["dense sigomid : (1, 1), [[0.60975546]]\n","dense tanh : (1, 1), [[0.9439984]]\n","dense  relu : (1, 1), [[0.6568093]] \n","\n","dense sigmoid manual : (1, 1), [[0.60975546]]\n"]}],"source":["x = tf.random.normal(shape=(1, 5))\n","\n","dense_sigmoid = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n","y_sigmoid = dense_sigmoid(x)\n","\n","dense_tanh = tf.keras.layers.Dense(units=1, activation=\"tanh\")\n","y_tanh = dense_tanh(x)\n","\n","dense_relu = tf.keras.layers.Dense(units=1, activation=\"relu\")\n","y_relu = dense_relu(x)\n","\n","print(f\"dense sigomid : {y_sigmoid.shape}, {y_sigmoid.numpy()}\")\n","print(f\"dense tanh : {y_tanh.shape}, {y_tanh.numpy()}\")\n","print(f\"dense  relu : {y_relu.shape}, {y_relu.numpy()} \\n\")\n","\n","W, B = dense_sigmoid.get_weights()\n","z = tf.linalg.matmul(x, W) + B\n","a = 1 / (1 + tf.math.exp(-z))\n","print(f\"dense sigmoid manual : {a.shape}, {a}\")"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1676525142091,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"DiD6zWQXnVUD","outputId":"41cb447e-7c0d-460a-cf4f-2b2f5dc43c2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["x : (8, 10), \n"," [[-2.5338194e-01  2.6184154e-01  9.3986297e-01  1.3035606e+00\n","  -1.1712273e+00 -3.8360506e-01  7.1698058e-01  1.6246510e-01\n","   8.8442403e-01  6.2292325e-01]\n"," [ 1.8556967e+00  2.0971987e+00  1.2805805e+00 -3.5841903e-01\n","  -1.4952463e+00 -3.4220162e-01  1.9791722e+00 -6.4121985e-01\n","   1.2445785e+00 -1.2151018e+00]\n"," [ 3.0525714e-01  5.9231079e-01 -3.2496724e-01 -8.0745691e-01\n","  -2.6264902e-02 -2.2079530e+00 -5.7939178e-01  2.3375511e-01\n","  -1.3496553e+00  2.7112098e+00]\n"," [ 1.6862184e+00  2.0033090e-01 -1.3142185e+00  5.6238097e-01\n","  -7.6806498e-01  7.8438526e-01 -3.4793407e-01 -1.0088878e+00\n","   5.4503191e-01  3.9363611e-01]\n"," [ 9.7062743e-01  1.3356717e+00  5.2292836e-01  8.2653487e-01\n","   1.1026736e+00  2.1133822e-01 -3.9874503e-01 -4.8700544e-01\n","  -1.7227203e+00  2.2217268e-01]\n"," [ 2.0820022e+00  5.7750922e-01  3.7943959e-02 -5.6936079e-01\n","   1.0169048e+00  4.7315855e-02 -2.1885068e+00  1.4651825e+00\n","  -2.1836336e-03  6.4512633e-02]\n"," [-7.4042898e-01  4.5506695e-01  1.9803399e+00 -4.6159780e-01\n","  -9.5013881e-01  8.4618598e-01  5.1530886e-01  6.4186889e-01\n","  -4.1044357e-01  1.4097852e+00]\n"," [ 1.2987049e+00  2.0335971e-01  1.2698892e+00  1.8629721e+00\n","  -8.4164441e-01 -1.1809975e-01 -2.0020676e+00  9.1111052e-01\n","   2.4830422e-01  1.7320423e-01]]\n","W : (10, 1) \n"," [[ 0.6009124 ]\n"," [-0.06721294]\n"," [ 0.2494095 ]\n"," [-0.40572327]\n"," [ 0.45133263]\n"," [ 0.18874389]\n"," [-0.7153027 ]\n"," [ 0.5662909 ]\n"," [ 0.64205855]\n"," [-0.00325948]]\n","B : (1,) \n"," [0.]\n"]}],"source":["N, n_feature = 8, 10\n","x = tf.random.normal(shape=(N, n_feature))\n","\n","dense = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n","y = dense(x)\n","\n","W, B = dense.get_weights() ## Mini-batch size는 weight, bias에 영향을 끼치지 않는다!!!\n","\n","print(f\"x : {x.shape}, \\n {x.numpy()}\")\n","print(f\"W : {W.shape} \\n {W}\")\n","print(f\"B : {B.shape} \\n {B}\")"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676525142355,"user":{"displayName":"김민준","userId":"08346406018640900317"},"user_tz":-540},"id":"u1j51ZbHptPk","outputId":"cc3acf14-5598-4270-bb19-4023f923bf3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["y : (8, 1) \n"," [[0.28487965]\n"," [0.43137264]\n"," [0.40926692]\n"," [0.56745225]\n"," [0.43260098]\n"," [0.9867993 ]\n"," [0.41661608]\n"," [0.88415277]]\n","y manual : (8, 1) \n","[[0.28487965]\n"," [0.43137264]\n"," [0.40926692]\n"," [0.56745225]\n"," [0.43260098]\n"," [0.9867993 ]\n"," [0.41661608]\n"," [0.88415277]]\n"]}],"source":["y_man = tf.linalg.matmul(x, W) + B\n","y_man = 1 / (1 + tf.math.exp(-y_man))\n","\n","print(f\"y : {y.shape} \\n {y.numpy()}\")\n","print(f\"y manual : {y_man.shape} \\n{y_man.numpy()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUhjVo9wrLtJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP9sptyrtYRuzokrC+QrzY5","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13"},"vscode":{"interpreter":{"hash":"40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"}}},"nbformat":4,"nbformat_minor":0}
