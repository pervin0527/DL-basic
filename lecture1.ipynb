{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPP2qkoDJonGB4vmenw54h1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## 1.Parametric Function\n","함수가 기본적으로 파라미터 θ를 포함하고 있다. 입력을 받으면 함수내 정의된 logic의 연산에 θ를 이용한다.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1Gj6ow44vICV_Ysuwp3R5EWzIUPWpflq1\">"],"metadata":{"id":"Le0CG-IM69YW"}},{"cell_type":"markdown","source":["일반적인 함수는 정의된 logic대로 연산결과를 출력하지만, parametric function은 함수가 보유중인 파라미터를 추가적으로 이용한다.  \n","따라서 θ값이 변하면(다르면) 동일한 함수여도 다른 결과를 얻게 된다."],"metadata":{"id":"FTwAqrRH_z6Q"}},{"cell_type":"markdown","source":["## 2.Tensor\n","텐서는 일반적으로 다차원 배열이나, 스칼라값도 가질 수 있다. 스칼라, 벡터, 행렬 그리고 그 이상의 고차원 배열들을 담는 그릇이자 하나의 단위가 텐서라고 이해하면 될 듯하다.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1YZ8xi6Cw3n6kVq3ucNb8CDpl_IZ5IfUH\">\n","\n","0차원 텐서에서 두 개의 실수간 덧셈, 곱셈을 기반으로 1차원, 2차원, 3차원 텐서에서의 연산으로 확장이 가능하며 새로운 연산을 정의할 수도 있다."],"metadata":{"id":"pcNPP1_yBFaT"}},{"cell_type":"markdown","source":["## 3.Dataset\n","통상적으로 한 개의 데이터는 row vector 형태로 다룬다.  \n","그리고 row vector 데이터들이 모여서(쌓여서) 하나의 데이터셋을 구성하게 된다.\n","<img src=\"https://drive.google.com/uc?export=download&id=1RAwlV3Aj-2Q6_vZRMXncKZzFnnGE88L_\">\n","\n","참고로 l<sub>i</sub>는 length of input. 즉 한 개의 데이터(1 row)의 길이를 의미한다."],"metadata":{"id":"jigfZlumCg0K"}},{"cell_type":"markdown","source":["## 3.Weighted Sum & Affine Transformation\n","<img src=\"https://drive.google.com/uc?export=download&id=1rtP6ZHbIhbKPrzUERmO2q1PAzgW13smW\" width=\"480\" height=\"640\">\n","\n","- weighted sum은 입력값 x에 함수가 보유중인 파라미터 w(weight)를 곱해준다. weight의 기능은 입력값 x가 z값에 얼마만큼의 영향을 주게될지 정해준다.\n","- Affine Transformation은 weighted sum에서 b(bias)라는 파라미터가 추가된 것."],"metadata":{"id":"OQZ_jAZ8NJn4"}},{"cell_type":"markdown","source":["이번에는 데이터 1개가 아니라 다수의 데이터에 대한 식을 알아보자.\n","<img src=\"https://drive.google.com/uc?export=download&id=174eUsZdhUgA3vUQ8hdALXt8RTxrkp68M\">\n","<img src=\"https://drive.google.com/uc?export=download&id=1UmyX5aEypKLyRby17R9BURhKzepzld9d\">\n","\n","데이터의 수가 늘어나도 함수 자체의 연산은 동일하다.  \n","weight가 하는 역할은 입력값 x<sub>1</sub>, x<sub>2</sub>, x<sub>n</sub> 들 각각이 함수값 z에 미치는 영향력을 지정하는 것이다.\n","\n","이때 중요한 사항은 입력 벡터 x<sub>l<sub>I</sub></sub>의 수와 가중치 벡터 w의 수가 같아야한다는 것이다.  \n","즉, 입력 벡터가 x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub> 이라면, 가중치 벡터의 형태는 w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>가 되는 것이다. bias는 1개만 존재.\n","\n","입력 데이터의 feature 수만큼, weight column이 생성된다."],"metadata":{"id":"hvfqmw1EPpRq"}},{"cell_type":"code","source":["## 1개 데이터, 1개의 값에 대한 Affine Transform.\n","import tensorflow as tf\n","\n","x = tf.constant([[10.]]) ## vector([10.])가 아니라 matrix([[10.]]) 형태임에 유의할 것. shape = (1, 1)\n","\n","dense = tf.keras.layers.Dense(units=1, activation=\"linear\") ## affine function\n","\n","y = dense(x) ## output. forward propagation + parameter initialization(x값이 입력되는 시점에 weight, bias가 초기화 된다.)\n","\n","W, B = dense.get_weights()\n","\n","## Manual\n","y_manual = tf.linalg.matmul(x, W) + B\n","\n","## print reuslt\n","print(f\"x : {x.shape}, {x.numpy()}\")\n","print(f\"W : {W.shape}, {W}\")\n","print(f\"B : {B.shape}, {B}\")\n","print(f\"y : {y.shape}, {y.numpy()}\")\n","print(f\"y manual : {y_manual.shape}, {y_manual}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WD-QFeq2Zvj5","executionInfo":{"status":"ok","timestamp":1676868181160,"user_tz":-540,"elapsed":13663,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"a238df62-2e38-418b-e06a-a70377c0c7b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x : (1, 1), [[10.]]\n","W : (1, 1), [[0.6688086]]\n","B : (1,), [0.]\n","y : (1, 1), [[6.6880856]]\n","y manual : (1, 1), [[6.6880856]]\n"]}]},{"cell_type":"code","source":["## self ##\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","\n","x = tf.constant([[1., 4., 7.]]) ## (1, 3) row vector\n","\n","dense = Dense(units=1, activation=\"linear\") ## (3, 1) column vector\n","y = dense(x) ## 1 by 1\n","\n","W, b = dense.get_weights()\n","print(f\"input : {x.shape} \\n {x} \\n\")\n","print(f\"Weight : {W.shape} \\n {W} \\n\")\n","print(f\"bias : {b.shape} \\n {b} \\n\")\n","print(f\"output : {y.shape} \\n {y}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M32TzvhwIWpm","executionInfo":{"status":"ok","timestamp":1677132533705,"user_tz":-540,"elapsed":306,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"94b502ca-2ee7-4353-a218-6f52e9f8d71b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["input : (1, 3) \n"," [[1. 4. 7.]] \n","\n","Weight : (3, 1) \n"," [[-0.21766675]\n"," [-1.0486946 ]\n"," [-0.42008948]] \n","\n","bias : (1,) \n"," [0.] \n","\n","output : (1, 1) \n"," [[-7.353071]]\n"]}]},{"cell_type":"code","source":["## weight, bias initializer\n","from tensorflow.keras.initializers import Constant\n","\n","w, b = tf.constant(10.), tf.constant(20.)\n","## Tensor를 만드는게 아니라 Layer의 parameter를 초기화 시키는 object를 만든 것.\n","w_init, b_init = Constant(w), Constant(b)\n","print(w_init, b_init)\n","\n","dense = tf.keras.layers.Dense(units=1, \n","                              activation=\"linear\", \n","                              kernel_initializer=w_init, \n","                              bias_initializer=b_init)\n","y = dense(x)\n","W, B = dense.get_weights()\n","\n","print(f\"y. : {y.shape}, {y}\")\n","print(f\"W : {W.shape}, {W}\")\n","print(f\"B : {B.shape}, {B}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-E1A7roafC6","executionInfo":{"status":"ok","timestamp":1676868975318,"user_tz":-540,"elapsed":4,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"27c0d2cd-4369-4cc1-dd75-22de4ae9d444"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<keras.initializers.initializers_v2.Constant object at 0x7f4ee381b310> <keras.initializers.initializers_v2.Constant object at 0x7f4ee37b5bb0>\n","y. : (1, 1), [[140.]]\n","W : (3, 1), [[10.]\n"," [10.]\n"," [10.]]\n","B : (1,), [20.]\n"]}]},{"cell_type":"code","source":["## 한 개의 row vector data. 10개의 feature.\n","x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10)\n","\n","dense = tf.keras.layers.Dense(units=1)\n","y = dense(x)\n","W, B = dense.get_weights()\n","\n","y_manual = tf.linalg.matmul(x, W) + B\n","\n","## print reuslt\n","print(f\"x : {x.shape} \\n {x.numpy()}\") ## row vector\n","print(f\"W : {W.shape} \\n {W}\") ## column vector\n","print(f\"B : {B.shape} \\n {B}\")\n","print(f\"y : {y.shape} \\n {y.numpy()}\")\n","print(f\"y manual : {y_manual.shape}, {y_manual}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDJIUHksdzn5","executionInfo":{"status":"ok","timestamp":1676869034041,"user_tz":-540,"elapsed":269,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"a9ed257d-0fa2-4224-a4ae-2f08998bea8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x : (1, 10) \n"," [[2.7111328  4.7499695  6.7036486  3.884046   2.8344262  4.377949\n","  0.80842614 0.01494527 6.9357643  0.3285551 ]]\n","W : (10, 1) \n"," [[-0.11228108]\n"," [ 0.13207024]\n"," [ 0.08529449]\n"," [ 0.05172127]\n"," [ 0.48589462]\n"," [-0.01613331]\n"," [-0.7165279 ]\n"," [ 0.5260306 ]\n"," [ 0.08768076]\n"," [ 0.41819018]]\n","B : (1,) \n"," [0.]\n","y : (1, 1) \n"," [[2.5763278]]\n","y manual : (1, 1), [[2.5763278]]\n"]}]},{"cell_type":"markdown","source":["## 4.Activation Function\n","\n","Affine Transformation을 거친 이후에, Activation function을 적용하게 된다.  \n","이는 activation function에 입력된 값이 적용한 활성화 함수의 연산에 따라 결과값이 결정되는 형태다.\n","<img src=\"https://drive.google.com/uc?export=download&id=1xP6YiARnabEQj2xz-rOXOYgPXl3JWBXq\">\n","<img src=\"https://drive.google.com/uc?export=download&id=12Wn0dTJzxkYh1G3Y232E8XaZ2NtKAmXn\">"],"metadata":{"id":"QcuGmvCXTQxT"}},{"cell_type":"code","source":["## input & Activation func.\n","\n","x = tf.random.normal(shape=(1, 5))\n","\n","sigmoid = tf.keras.layers.Activation(\"sigmoid\")\n","tanh = tf.keras.layers.Activation(\"tanh\")\n","relu = tf.keras.layers.Activation(\"relu\")\n","\n","y_sigmoid = sigmoid(x)\n","y_tanh = tanh(x)\n","y_relu = relu(x)\n","\n","print(f\"x : {x.shape}, {x.numpy()} \\n\")\n","print(f\"Sigmoid : {y_sigmoid.shape}, {y_sigmoid.numpy()}\")\n","print(f\"Tanh : {y_tanh.shape}, {y_tanh.numpy()}\")\n","print(f\"ReLU : {y_relu.shape}, {y_relu.numpy()} \\n\")\n","\n","y_sigmoid_man = 1 / (1 + tf.math.exp(-x))\n","y_tanh_man = (tf.exp(x) - tf.exp(-x)) / (tf.exp(x) + tf.exp(-x))\n","y_relu_man = tf.math.maximum(x, 0)\n","\n","print(f\"Sigmoid manual : {y_sigmoid_man.shape}, {y_sigmoid_man.numpy()}\")\n","print(f\"Tanh manual : {y_tanh_man.shape}, {y_tanh_man.numpy()}\")\n","print(f\"ReLU manual : {y_relu_man.shape}, {y_relu_man.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iv1u3gjne6S9","executionInfo":{"status":"ok","timestamp":1676523694497,"user_tz":-540,"elapsed":279,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"10fb3109-334e-4fff-d285-65fee0a5c13c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x : (1, 5), [[ 0.47400722  0.68043196  0.26013425 -0.27689335  1.4365736 ]] \n","\n","Sigmoid : (1, 5), [[0.61633176 0.6638351  0.5646693  0.43121555 0.8079235 ]]\n","Tanh : (1, 5), [[ 0.44143143  0.59180015  0.2544211  -0.27002737  0.89300585]]\n","ReLU : (1, 5), [[0.47400722 0.68043196 0.26013425 0.         1.4365736 ]] \n","\n","Sigmoid manual : (1, 5), [[0.61633176 0.6638351  0.5646693  0.43121555 0.8079235 ]]\n","Tanh manual : (1, 5), [[ 0.44143137  0.59180015  0.25442111 -0.27002743  0.89300585]]\n","ReLU manual : (1, 5), [[0.47400722 0.68043196 0.26013425 0.         1.4365736 ]]\n"]}]},{"cell_type":"code","source":["## Affine Transform with Activation Func.\n","x = tf.random.normal(shape=(1, 5))\n","\n","dense_sigmoid = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n","y_sigmoid = dense_sigmoid(x)\n","\n","dense_tanh = tf.keras.layers.Dense(units=1, activation=\"tanh\")\n","y_tanh = dense_tanh(x)\n","\n","dense_relu = tf.keras.layers.Dense(units=1, activation=\"relu\")\n","y_relu = dense_relu(x)\n","\n","print(f\"dense sigomid : {y_sigmoid.shape}, {y_sigmoid.numpy()}\")\n","print(f\"dense tanh : {y_tanh.shape}, {y_tanh.numpy()}\")\n","print(f\"dense  relu : {y_relu.shape}, {y_relu.numpy()} \\n\")\n","\n","W, B = dense_sigmoid.get_weights()\n","z = tf.linalg.matmul(x, W) + B\n","a = 1 / (1 + tf.math.exp(-z))\n","print(f\"dense sigmoid manual : {a.shape}, {a}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08iyFswxifp-","executionInfo":{"status":"ok","timestamp":1676524172688,"user_tz":-540,"elapsed":257,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"4b2ddee9-b65d-4fea-ed0e-1d967a721c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dense sigomid : (1, 1), [[0.60975546]]\n","dense tanh : (1, 1), [[0.9439984]]\n","dense  relu : (1, 1), [[0.6568093]] \n","\n","dense sigmoid manual : (1, 1), [[0.60975546]]\n"]}]},{"cell_type":"code","source":["## self ##\n","\n","x = tf.random.normal(shape=(1, 10)) ## 1 by 10.\n","\n","dense_sigmoid = Dense(units=1, activation=\"sigmoid\") ## weights : 10 by 1, bias : 1 activation : sigmoid\n","y = dense_sigmoid(x)\n","W, b = dense_sigmoid.get_weights()\n","print(f\"W : {W.shape} \\n {W}\")\n","print(f\"b : {b.shape} \\n {b}\")\n","print(f\"y tf : {y.shape} \\n {y.numpy()}\")\n","\n","y_man = tf.linalg.matmul(x, W) + b ## Affine Transform.\n","y_man = 1 / (1 + tf.math.exp(-y_man)) ## Sigmoid func.\n","print(f\"y_man : {y_man.shape} \\n {y}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61MymjJvMJXc","executionInfo":{"status":"ok","timestamp":1676871718516,"user_tz":-540,"elapsed":733,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"3dd74aaf-16d2-4acd-b1f6-7538dcc5e5f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W : (10, 1) \n"," [[-0.31999266]\n"," [-0.6403414 ]\n"," [ 0.38386375]\n"," [-0.5370061 ]\n"," [ 0.25103617]\n"," [-0.5355664 ]\n"," [ 0.31952423]\n"," [-0.26529628]\n"," [ 0.7364002 ]\n"," [-0.04152161]]\n","b : (1,) \n"," [0.]\n","y tf : (1, 1) \n"," [[0.5928964]]\n","y_man : (1, 1) \n"," [[0.5928964]]\n"]}]},{"cell_type":"markdown","source":["## 5.Mini-Batch\n","\n","mini batch는 데이터를 하나의 묶음으로 입력하는 것을 의미한다. 예를 들어 batch-size가 32라면 1개의 데이터 묶음 속에 32개의 데이터가 들어가 있다.  \n","데이터 묶음 속 각각의 데이터가 Affine transform, Activation function을 거치게 되는데 이때 함수들이 가지고 있는 weight, bias는 값이 변하지 않음에 유의할 것.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=10FPGwD4wM-62ziN30kdVB4VaOaxpfs_e\">\n","<img src=\"https://drive.google.com/uc?export=download&id=14sdWrA81UoT3XViGCA9WMbplrf9FdbD6\">"],"metadata":{"id":"dc_XysmgVFt3"}},{"cell_type":"code","source":["## Affine Trans + Activation func with Mini-batch\n","N, n_feature = 3, 5\n","x = tf.random.normal(shape=(N, n_feature))\n","\n","dense = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n","y = dense(x)\n","\n","W, B = dense.get_weights() ## Mini-batch size는 weight, bias에 영향을 끼치지 않는다!!!\n","\n","print(f\"x : {x.shape} \\n {x.numpy()}\")\n","print(f\"W : {W.shape} \\n {W}\")\n","print(f\"B : {B.shape} \\n {B}\")\n","print(f\"y : {y.shape} \\n {y.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiD6zWQXnVUD","executionInfo":{"status":"ok","timestamp":1677133613475,"user_tz":-540,"elapsed":4,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"7fec4b81-ae23-4db3-c632-b1d4f02dea99"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["x : (3, 5) \n"," [[ 0.454314   -0.6143074  -0.19492248 -0.22771174 -1.7071912 ]\n"," [-0.1889215   0.80534655 -2.092378   -1.4967377  -0.6269125 ]\n"," [-1.3200445  -0.09606645 -0.9125424   0.7046709   0.56615615]]\n","W : (5, 1) \n"," [[-0.8701072 ]\n"," [-0.9129729 ]\n"," [ 0.10068583]\n"," [-0.88756704]\n"," [-0.8946471 ]]\n","B : (1,) \n"," [0.]\n","y : (3, 1) \n"," [[0.8670774]\n"," [0.7517131]\n"," [0.5031133]]\n"]}]},{"cell_type":"code","source":["y_man = tf.linalg.matmul(x, W) + B\n","y_man = 1 / (1 + tf.math.exp(-y_man))\n","\n","print(f\"y tensorflow: {y.shape} \\n {y.numpy()} \\n\")\n","print(f\"y manual : {y_man.shape} \\n{y_man.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1j51ZbHptPk","executionInfo":{"status":"ok","timestamp":1677133677148,"user_tz":-540,"elapsed":309,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"0f9bc5b2-c9fd-46e2-afe2-7f2740931881"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["y tensorflow: (3, 1) \n"," [[0.8670774]\n"," [0.7517131]\n"," [0.5031133]] \n","\n","y manual : (3, 1) \n","[[0.8670774]\n"," [0.7517131]\n"," [0.5031133]]\n"]}]},{"cell_type":"code","source":["## self ##\n","X = tf.random.normal(shape=(10, 5)) ## batch-size = 10, feature in row wise = 5\n","\n","dense = Dense(units=1, activation=(\"sigmoid\"))\n","Y = dense(X)\n","\n","W, b = dense.get_weights()\n","print(f\"X : {X.shape} \\n {X.numpy()}\")\n","print(f\"W : {W.shape} \\n {W}\")\n","print(f\"b : {b.shape} \\n {b}\")\n","print(f\"Y : {Y.shape} \\n {Y.numpy()}\")\n","\n","Z = tf.linalg.matmul(X, W) + b\n","A = 1 / (1 + tf.math.exp(-Z))\n","print(f\"A : {A.shape} \\n {A}\")"],"metadata":{"id":"EUhjVo9wrLtJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676871748949,"user_tz":-540,"elapsed":311,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"033a73a1-b544-4939-8e6e-8bfd0097e40f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X : (10, 5) \n"," [[ 0.05838945 -0.01629276  0.24191903  0.49484608  0.8030093 ]\n"," [ 2.4908857   0.76183707  2.1102815   0.9737939  -1.1018577 ]\n"," [-0.5412256  -0.04079812 -1.490813   -0.7238365  -0.29986432]\n"," [-0.76648015  0.50365984  0.02132273  1.4990809   0.80910254]\n"," [-0.7634293   0.67730844 -0.46383393 -1.389235    2.7689056 ]\n"," [-1.2981669  -1.6906124   0.4484961   0.9054918   1.177951  ]\n"," [ 0.03938768 -0.6596372  -1.0927767   0.40590832 -0.12904261]\n"," [ 0.04981457  2.2720761  -1.2451718  -0.367394    0.46084523]\n"," [ 0.7832895  -0.02164987 -1.1234018   1.6135793  -0.76239365]\n"," [ 2.1102645   0.04436247  0.43940756  0.4966496   1.9832909 ]]\n","W : (5, 1) \n"," [[ 0.32691073]\n"," [ 0.38050508]\n"," [ 0.99193215]\n"," [-0.9726291 ]\n"," [ 0.00578141]]\n","b : (1,) \n"," [0.]\n","Y : (10, 1) \n"," [[0.44428155]\n"," [0.9041253 ]\n"," [0.27508962]\n"," [0.18374968]\n"," [0.7140779 ]\n"," [0.18291956]\n"," [0.15217751]\n"," [0.5014245 ]\n"," [0.0801484 ]\n"," [0.6617318 ]]\n","A : (10, 1) \n"," [[0.44428155]\n"," [0.9041253 ]\n"," [0.27508962]\n"," [0.18374968]\n"," [0.7140779 ]\n"," [0.18291956]\n"," [0.15217751]\n"," [0.5014245 ]\n"," [0.0801484 ]\n"," [0.6617318 ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"O3CmMQR3VDnq"},"execution_count":null,"outputs":[]}]}