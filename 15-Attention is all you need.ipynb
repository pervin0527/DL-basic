{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15-Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.Define Vocab & Dataset](#1)\n",
    " - [1-1.Build Vocab(Tokenizer)](#1-1)\n",
    " - [1-2.Build Torch Dataset & DataLoader](#1-2)\n",
    "\n",
    "[2.Word Embedding, Positional Encoding](#2)\n",
    "\n",
    "[3.Transformer Embedding](#3)\n",
    "\n",
    "[4.Multi Head Self-Attention](#4)\n",
    "\n",
    "[5.Feed Forward Layer](#5)\n",
    "\n",
    "[6.LayerNorm & Residual Connection](#6)\n",
    "\n",
    "[7.Encoder](#7)\n",
    "\n",
    "[8.Decoder](#8)\n",
    "\n",
    "[9.Transformer](#9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext import transforms\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from utils.data_utils import load_pickle, download_multi30k, make_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/pervinco/Datasets\"\n",
    "SAVE_DIR = \"./runs/Transformer\"\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 5e-9\n",
    "ADAM_EPS = 5e-9\n",
    "SCHEDULER_FACTOR = 0.9\n",
    "SCHEDULER_PATIENCE = 10\n",
    "WARM_UP_STEP = 100\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = min([os.cpu_count(), BATCH_SIZE if BATCH_SIZE > 1 else 0, 8])\n",
    "\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "FFN_DIM = 2048\n",
    "MAX_SEQ_LEN = 256\n",
    "DROP_PROB = 0.1\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1.Define Vocab & Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1-1\"></a>\n",
    "### 1-1.Build Vocab(Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1-2\"></a>\n",
    "### 1-2.Build Torch Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi30kDataset:\n",
    "    UNK, UNK_IDX = \"<unk>\", 0\n",
    "    PAD, PAD_IDX = \"<pad>\", 1\n",
    "    SOS, SOS_IDX = \"<sos>\", 2\n",
    "    EOS, EOS_IDX = \"<eos>\", 3\n",
    "    SPECIALS = {UNK : UNK_IDX, PAD : PAD_IDX, SOS : SOS_IDX, EOS : EOS_IDX}\n",
    "\n",
    "    URL = \"https://github.com/multi30k/dataset/raw/master/data/task1/raw\"\n",
    "    FILES = [\"test_2016_flickr.de.gz\",\n",
    "             \"test_2016_flickr.en.gz\",\n",
    "             \"train.de.gz\",\n",
    "             \"train.en.gz\",\n",
    "             \"val.de.gz\",\n",
    "             \"val.en.gz\"]\n",
    "    \n",
    "\n",
    "    def __init__(self, data_dir, source_language=\"en\", target_language=\"de\", max_seq_len=256, vocab_min_freq=2):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_min_freq = vocab_min_freq\n",
    "        self.source_language = source_language\n",
    "        self.target_language = target_language\n",
    "\n",
    "        ## 데이터 파일 로드.\n",
    "        self.train = load_pickle(f\"{data_dir}/cache/train.pkl\")\n",
    "        self.valid = load_pickle(f\"{data_dir}/cache/val.pkl\")\n",
    "        self.test = load_pickle(f\"{data_dir}/cache/test.pkl\")\n",
    "\n",
    "        ## tokenizer 정의.\n",
    "        if self.source_language == \"en\":\n",
    "            self.source_tokenizer = get_tokenizer(\"spacy\", \"en_core_web_sm\")\n",
    "            self.target_tokenizer = get_tokenizer(\"spacy\", \"de_core_news_sm\")\n",
    "        else:\n",
    "            self.source_tokenizer = get_tokenizer(\"spacy\", \"de_core_news_sm\")\n",
    "            self.target_tokenizer = get_tokenizer(\"spacy\", \"en_core_web_sm\")\n",
    "\n",
    "        self.src_vocab, self.trg_vocab = self.get_vocab(self.train)\n",
    "        self.src_transform = self.get_transform(self.src_vocab)\n",
    "        self.trg_transform = self.get_transform(self.trg_vocab)\n",
    "\n",
    "\n",
    "    def yield_tokens(self, train_dataset, is_src):\n",
    "        for text_pair in train_dataset:\n",
    "            if is_src:\n",
    "                yield [str(token) for token in self.source_tokenizer(text_pair[0])]\n",
    "            else:\n",
    "                yield [str(token) for token in self.target_tokenizer(text_pair[1])]\n",
    "\n",
    "\n",
    "    def get_vocab(self, train_dataset):\n",
    "        src_vocab_pickle = f\"{self.data_dir}/cache/vocab_{self.source_language}.pkl\"\n",
    "        trg_vocab_pickle = f\"{self.data_dir}/cache/vocab_{self.target_language}.pkl\"\n",
    "\n",
    "        if os.path.exists(src_vocab_pickle) and os.path.exists(trg_vocab_pickle):\n",
    "            src_vocab = load_pickle(src_vocab_pickle)\n",
    "            trg_vocab = load_pickle(trg_vocab_pickle)\n",
    "        else:\n",
    "            src_vocab = build_vocab_from_iterator(self.yield_tokens(train_dataset, True), min_freq=self.vocab_min_freq, specials=self.SPECIALS.keys())\n",
    "            src_vocab.set_default_index(self.UNK_IDX)\n",
    "\n",
    "            trg_vocab = build_vocab_from_iterator(self.yield_tokens(train_dataset, False), min_freq=self.vocab_min_freq, specials=self.SPECIALS.keys())\n",
    "            trg_vocab.set_default_index(self.UNK_IDX)\n",
    "            \n",
    "        return src_vocab, trg_vocab\n",
    "    \n",
    "\n",
    "    def get_transform(self, vocab):\n",
    "        return transforms.Sequential(transforms.VocabTransform(vocab),\n",
    "                                     transforms.Truncate(self.max_seq_len-2),\n",
    "                                     transforms.AddToken(token=self.SOS_IDX, begin=True),\n",
    "                                     transforms.AddToken(token=self.EOS_IDX, begin=False),\n",
    "                                     transforms.ToTensor(padding_value=self.PAD_IDX))\n",
    "\n",
    "\n",
    "    def collate_fn(self, pairs):\n",
    "        src = [self.source_tokenizer(pair[0]) for pair in pairs]\n",
    "        trg = [self.target_tokenizer(pair[1]) for pair in pairs]\n",
    "        batch_src = self.src_transform(src)\n",
    "        batch_trg = self.trg_transform(trg)\n",
    "\n",
    "        return (batch_src, batch_trg)\n",
    "    \n",
    "\n",
    "    def get_iter(self, batch_size, num_workers):\n",
    "        train_iter = DataLoader(self.train, collate_fn=self.collate_fn, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        valid_iter = DataLoader(self.valid, collate_fn=self.collate_fn, batch_size=batch_size, num_workers=num_workers)\n",
    "        test_iter = DataLoader(self.test, collate_fn=self.collate_fn, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "        return train_iter, valid_iter, test_iter\n",
    "    \n",
    "    \n",
    "    def translate(self, model, src_sentence: str, decode_func):\n",
    "        model.eval()\n",
    "        src = self.src_transform([self.source_tokenizer(src_sentence)]).view(1, -1)\n",
    "        num_tokens = src.shape[1]\n",
    "        trg_tokens = decode_func(model, src, max_len=num_tokens + 5, start_symbol=self.SOS_IDX, end_symbol=self.EOS_IDX).flatten().cpu().numpy()\n",
    "        trg_sentence = \" \".join(self.trg_vocab.lookup_tokens(trg_tokens))\n",
    "\n",
    "        return trg_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pervinco/Datasets/Multi30k is already exist.\n",
      "/home/pervinco/Datasets/Multi30k/cache is already exist.\n"
     ]
    }
   ],
   "source": [
    "download_multi30k(DATA_DIR)\n",
    "make_cache(f\"{DATA_DIR}/Multi30k\")\n",
    "\n",
    "DATASET = Multi30kDataset(data_dir=f\"{DATA_DIR}/Multi30k\", source_language=SRC_LANGUAGE,  target_language=TGT_LANGUAGE,  max_seq_len=MAX_SEQ_LEN, vocab_min_freq=2)\n",
    "train_iter, valid_iter, test_iter = DATASET.get_iter(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24])\n",
      "torch.Size([32, 23])\n",
      "[   2    6   33    7    4   26   11   23 1567   11   96 5741   45    4\n",
      "  425   14  515    9 1132  161   13   44    5    3]\n",
      "[   2   48  390  128   10 1010  119   70    8   74 1372    5    3    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[   2   19   53   17   55   70    4  425 1887    5    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[   2    6   12   38 1427   15   27  861 2625   18    8  485    5    3\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[  2   6  23  34 206 121   8  90   3   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2    6   60   35   10  171    4 5780 1180  102   56    4   60   26\n",
      " 1917    5    3    1    1    1    1    1    1    1]\n",
      "[   2    6   16   21    4   96 4101  238    4  157   41    4 3243  362\n",
      "    5    3    1    1    1    1    1    1    1    1]\n",
      "[   2   19   37   17  294   28 5033    9    4  940    5    3    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[  2   6  12   7   4  26 194  10  42   5   3   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2  57  25  37  17 171   4 210 651   9   4  61 693 350   5   3   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2    6   16   21    4   23   24  177    7    8  104   11  768   77\n",
      "   44 1084    5    3    1    1    1    1    1    1]\n",
      "[  2   6  12  94  20   4  98   7  43  13   4  61 907   5   3   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2   49  398   12    7 1064   10  737    4   75   58  622    4 2413\n",
      "    5    3    1    1    1    1    1    1    1    1]\n",
      "[   2 2474   17  254   18  468   87  131    5    3    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[   2    6   12    7    4   30   11   26  992 1753    7    4   30  223\n",
      "    5    3    1    1    1    1    1    1    1    1]\n",
      "[  2 142  37  17  38 434  11 268   5   3   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2    6  196 1337   21    4   23   24   11   26 2690  133   27  399\n",
      "   85   52   13   27  216    9    8 2651    5    3]\n",
      "[   2    6   12   14    4   23   69   11    4 1324 1417  189   10  129\n",
      "    9    8  590    5    3    1    1    1    1    1]\n",
      "[  2 552  13  22  76   7  26 489 105  40   3   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2  19  37  17   0  85  59   4  16 224 155   5   3   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2   6  25  12 597   9   4 672   5   3   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2 939 106  17   7 338  11  17  38  89 375   5   3   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2   6  16  10 308   4 418   9   4 346  40   5   3   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[  2 142  22  17  20   4   0 256 613  66  64  37   5   3   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2  612 3912    4   91  562  339   36    9    4 1146  362    5    3\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[  2  48 128  10  21  87 968  13 933  10  42   5   3   1   1   1   1   1\n",
      "   1   1   1   1   1   1]\n",
      "[   2    6   12   14  146   11    4   51 1780  774  744    9    8  365\n",
      "    5    3    1    1    1    1    1    1    1    1]\n",
      "[   2    6  806    7    4   63   84  298 1586   13    4  602 1790  186\n",
      "   16    5    3    1    1    1    1    1    1    1]\n",
      "[   2   82   17  621   85    4   98   13  131   11   56    4 1605    0\n",
      "   47    5    3    1    1    1    1    1    1    1]\n",
      "[   2    6  453   11  247    7    4 1189    7   43   13    4   79   14\n",
      "   22   42  230    5    3    1    1    1    1    1]\n",
      "[   2   19   22 1703   54  296   20    4  203    5    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[   2    6  785   12   31    9    4 1041   47    4   88    5    3    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n"
     ]
    }
   ],
   "source": [
    "sample_src, sample_tgt = None, None\n",
    "for src, trg in train_iter:\n",
    "    print(src.shape)\n",
    "    print(trg.shape)\n",
    "    \n",
    "    for s in src.numpy():\n",
    "        print(s)\n",
    "\n",
    "    sample_src = src\n",
    "    sample_tgt = trg\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2.Word Embedding, Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Embedding\n",
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model) ## 임베딩을 학습 과정에서 조정하는 임베딩 층.\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## 임베딩 벡터에서 값이 너무 큰 원소를 억제하기 위해 math.sqrt(self.d_model)를 곱한다.\n",
    "        out = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24, 512])\n"
     ]
    }
   ],
   "source": [
    "word_embedding_layer = WordEmbedding(D_MODEL, len(DATASET.src_vocab))\n",
    "\n",
    "embedded_sample_src = word_embedding_layer(sample_src)\n",
    "print(embedded_sample_src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=256, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        ## positional encoding 결과를 담을 텐서. -> [max_seq_len, d_model]\n",
    "        encoding = torch.zeros(max_seq_len, d_model, requires_grad=False)\n",
    "\n",
    "        ## 0부터 max_seq_len-1까지의 연속된 정수값을 포함하는 1차원 텐서. -> [max_seq_len, 1]\n",
    "        position = torch.arange(0, max_seq_len).float().unsqueeze(1)\n",
    "        \n",
    "        ## 10000**(2i/d_model) == e**(log(10000) * 2i / d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)) \n",
    "\n",
    "        ## i가 홀수일 때는 cos함수, j가 짝수일 때는 sin함수.\n",
    "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        ## [1, max_seq_len, d_model]\n",
    "        self.encoding = encoding.unsqueeze(0).to(device) \n",
    "\n",
    "    def forward(self, x):\n",
    "        ## x : Word Embedded Vector\n",
    "        _, seq_len, _ = x.size() ## [batch_size, max_seq_len, d_model]\n",
    "        pos_embed = self.encoding[:, :seq_len, :] ## slicing [1, seq_len, d_model]\n",
    "\n",
    "        out = x + pos_embed ## word embedded vector에 positional encoding값을 더함.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24, 512])\n"
     ]
    }
   ],
   "source": [
    "positional_encoding_layer = PositionalEncoding(D_MODEL, MAX_SEQ_LEN)\n",
    "\n",
    "pe_embedded = positional_encoding_layer(embedded_sample_src)\n",
    "print(pe_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3.Transformer Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, word_embedding_layer, positional_encoding_layer, drop_prob=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Sequential(word_embedding_layer, positional_encoding_layer)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.embedding(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24, 512])\n"
     ]
    }
   ],
   "source": [
    "transformer_embedding_layer = TransformerEmbedding(word_embedding_layer, positional_encoding_layer)\n",
    "embedded_input_matrix = transformer_embedding_layer(sample_src)\n",
    "\n",
    "print(embedded_input_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "## 4.Multi Head Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, drop_prob=0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        ## Embedded vector를 Q, K, V 행렬로 변환하기 위한 Layers\n",
    "        self.q_fc = nn.Linear(d_model, d_model) # (d_model, d_model)\n",
    "        self.k_fc = nn.Linear(d_model, d_model) # (d_model, d_model)\n",
    "        self.v_fc = nn.Linear(d_model, d_model) # (d_model, d_model)\n",
    "\n",
    "        ## output layer\n",
    "        self.out_fc = nn.Linear(d_model, d_model) # (d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "\n",
    "    def calculate_attention(self, query, key, value, mask):\n",
    "        ## Q, K, V: (batch_size, num_heads, seq_len, d_k)\n",
    "        ## Padding Mask : (batch_size, seq_len, seq_len)\n",
    "        d_k = key.shape[-1]\n",
    "        attention_score = torch.matmul(query, key.transpose(-2, -1)) # Attention Score. Q x K^T, (n_batch, num_heads, seq_len, seq_len)\n",
    "        attention_score = attention_score / math.sqrt(d_k) ## Scaling\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_score = attention_score.masked_fill(mask==0, -1e9)\n",
    "            \n",
    "        attention_prob = F.softmax(attention_score, dim=-1) ## Attention Distribution. (n_batch, num_heads, seq_len, seq_len)\n",
    "        attention_prob = self.dropout(attention_prob)\n",
    "        out = torch.matmul(attention_prob, value) ## Attention Value. (n_batch, num_heads, seq_len, d_k)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        ## (query, key, value)는 동일한 input tensor : (n_batch, seq_len, d_model)\n",
    "        ## transform(x, fc)가 Q, K, V로 변환.\n",
    "        ## mask: (n_batch, seq_len, seq_len)\n",
    "        # return value: (n_batch, num_heads, seq_len, d_k)\n",
    "        n_batch = query.size(0)\n",
    "\n",
    "        def transform(x, fc): # (n_batch, seq_len, d_model)\n",
    "            out = fc(x)       # (n_batch, seq_len, d_model)\n",
    "\n",
    "            # (n_batch, seq_len, num_heads, d_k)\n",
    "            out = out.view(n_batch, -1, self.num_heads, self.d_model // self.num_heads)\n",
    "            out = out.transpose(1, 2) # (n_batch, num_heads, seq_len, d_k)\n",
    "\n",
    "            return out\n",
    "\n",
    "        query = transform(query, self.q_fc) # (n_batch, num_heads, seq_len, d_k)\n",
    "        key = transform(key, self.k_fc)       # (n_batch, num_heads, seq_len, d_k)\n",
    "        value = transform(value, self.v_fc) # (n_batch, num_heads, seq_len, d_k)\n",
    "\n",
    "        out = self.calculate_attention(query, key, value, mask) # (n_batch, num_heads, seq_len, d_k)\n",
    "        out = out.transpose(1, 2) # (n_batch, seq_len, num_heads, d_k)\n",
    "        out = out.contiguous().view(n_batch, -1, self.d_model) # (n_batch, seq_len, d_model)\n",
    "        out = self.out_fc(out) # (n_batch, seq_len, d_model)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5.Feed Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, d_embed, d_ff, drop_prob=0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_embed, d_ff)   # (d_embed, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "        self.fc2 = nn.Linear(d_ff, d_embed) # (d_ff, d_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6.LayerNorm & Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_norm = nn.LayerNorm(D_MODEL, eps=1e-5)\n",
    "decoder_norm = nn.LayerNorm(D_MODEL, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnectionLayer(nn.Module):\n",
    "    def __init__(self, norm, drop_prob=0):\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, sub_layer): ## 입력 텐서와 sublayer를 입력 받는 것에 주목.\n",
    "        out = x\n",
    "        out = self.norm(out)\n",
    "        out = sub_layer(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x\n",
    "\n",
    "        # out = x\n",
    "        # out = sub_layer(out)\n",
    "        # out = self.dropout(out)\n",
    "        # out = self.norm(x + out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7.Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention, ffn, norm, drop_prob=0):\n",
    "        \"\"\"\n",
    "        self_attention : Self-Attention Layer 객체\n",
    "        ffn : FeedForward Layer 객체\n",
    "        norm : LayerNorm 겍체\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        ## 여기서 copy.deepcopy()는 하나의 layer 객체를 서로 다른 객체로 복사하기 위함.\n",
    "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), drop_prob)\n",
    "\n",
    "        self.ffn = ffn\n",
    "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), drop_prob)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        ## src : [batch_size, max_seq_len, d_model]\n",
    "        out = src\n",
    "\n",
    "        ## Self-Attention이므로 query, key, value가 모두 out으로 동일.\n",
    "        ## 이 때, lambda가 적용되는 이유는 순환의 목적이 아니라 reisdual 객체 내부에서 필요한 시점에 호출하기 위함.\n",
    "        out = self.residual1(out, lambda out : self.self_attention(query=out, key=out, value=out, mask=src_mask))\n",
    "        out = self.residual2(out, self.ffn)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_block, num_layer, norm):\n",
    "        super().__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_block) for _ in range(self.num_layer)])\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        out = src\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, src_mask)\n",
    "            \n",
    "        out = self.norm(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "## 8.Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, ffn, norm, drop_prob=0):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        self_attention : Masked Multi Head Self Attention 객체\n",
    "        cross_attention : Encoder - Decoder Multi Head Self Attention 객체\n",
    "        ffn : FeedForward Layer 객체\n",
    "        norm : LayerNorm 객체\n",
    "        \"\"\"\n",
    "        self.self_attention = self_attention\n",
    "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), drop_prob)\n",
    "        self.cross_attention = cross_attention\n",
    "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), drop_prob)\n",
    "        self.ffn = ffn\n",
    "        self.residual3 = ResidualConnectionLayer(copy.deepcopy(norm), drop_prob)\n",
    "\n",
    "    def forward(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
    "        out = tgt\n",
    "        out = self.residual1(out, lambda out: self.self_attention(query=out, key=out, value=out, mask=tgt_mask))\n",
    "        out = self.residual2(out, lambda out: self.cross_attention(query=out, key=encoder_out, value=encoder_out, mask=src_tgt_mask))\n",
    "        out = self.residual3(out, self.ffn)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_block, num_layer, norm):\n",
    "        super().__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(decoder_block) for _ in range(self.num_layer)])\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, trg, encoder_out, trg_mask, src_trg_mask):\n",
    "        out = trg\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, encoder_out, trg_mask, src_trg_mask)\n",
    "        out = self.norm(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "## 9.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_embed, trg_embed, encoder, decoder, generator):\n",
    "        super().__init__()\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.generator = generator\n",
    "\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "\n",
    "    def decode(self, trg, encoder_out, trg_mask, src_trg_mask):\n",
    "        return self.decoder(self.trg_embed(trg), encoder_out, trg_mask, src_trg_mask)\n",
    "\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        src_trg_mask = self.make_src_trg_mask(src, trg)\n",
    "        encoder_out = self.encode(src, src_mask)\n",
    "        decoder_out = self.decode(trg, encoder_out, trg_mask, src_trg_mask)\n",
    "        out = self.generator(decoder_out)\n",
    "        out = F.log_softmax(out, dim=-1)\n",
    "\n",
    "        return out, decoder_out\n",
    "\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        pad_mask = self.make_pad_mask(src, src)\n",
    "        \n",
    "        return pad_mask\n",
    "\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        pad_mask = self.make_pad_mask(trg, trg)\n",
    "        seq_mask = self.make_subsequent_mask(trg, trg)\n",
    "\n",
    "        return pad_mask & seq_mask\n",
    "\n",
    "\n",
    "    def make_src_trg_mask(self, src, trg):\n",
    "        pad_mask = self.make_pad_mask(trg, src)\n",
    "\n",
    "        return pad_mask\n",
    "\n",
    "\n",
    "    def make_pad_mask(self, query, key, pad_idx=1):\n",
    "        \"\"\"\n",
    "        Padding Mask\n",
    "            query: (n_batch, query_seq_len)\n",
    "            key: (n_batch, key_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        query_seq_len, key_seq_len = query.size(1), key.size(1) ## query_seq_len, key_seq_len\n",
    "\n",
    "        ## ne : pad_idx가 아닌 원소들을 찾아 True/False인 텐서를 만든다.\n",
    "        key_mask = key.ne(pad_idx).unsqueeze(1).unsqueeze(2)  # (n_batch, 1, 1, key_seq_len)\n",
    "\n",
    "        ## 세번째 차원을 쿼리 시퀀스 길이에 맞춰 반복해서 쌓는다.\n",
    "        key_mask = key_mask.repeat(1, 1, query_seq_len, 1)    # (n_batch, 1, query_seq_len, key_seq_len)\n",
    "\n",
    "        ## ne : pad_idx가 아닌 원소들을 찾아 True/False인 텐서를 만든다.\n",
    "        query_mask = query.ne(pad_idx).unsqueeze(1).unsqueeze(3)  # (n_batch, 1, query_seq_len, 1)\n",
    "        query_mask = query_mask.repeat(1, 1, 1, key_seq_len)  # (n_batch, 1, query_seq_len, key_seq_len)\n",
    "\n",
    "        mask = key_mask & query_mask ## 두 행렬에서 True인 원소만 True로.\n",
    "        mask.requires_grad = False\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def make_subsequent_mask(self, query, key):\n",
    "        \"\"\"\n",
    "        Look-Ahead Mask\n",
    "            query : (batch_size, query_seq_len)\n",
    "            key : (batch_size, key_seq_len)\n",
    "        \"\"\"\n",
    "        query_seq_len, key_seq_len = query.size(1), key.size(1)\n",
    "\n",
    "        ## shape이 query_seq_len, key_seq_len인 lower-triangular matrix를 만든다. k는 주대각원소의 위쪽에 있는 원소값.\n",
    "        tril = np.tril(np.ones((query_seq_len, key_seq_len)), k=0).astype('uint8') # lower triangle without diagonal\n",
    "        mask = torch.tensor(tril, dtype=torch.bool, requires_grad=False, device=query.device) ## boolean type의 텐서로 변환.\n",
    "\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(src_vocab_size,\n",
    "                trg_vocab_size, \n",
    "                max_seq_len=256,\n",
    "                d_model=512, \n",
    "                num_layer=6, \n",
    "                num_heads=8, \n",
    "                d_ff=2048, \n",
    "                norm_eps=1e-5,\n",
    "                drop_prob=0.1, \n",
    "                device=torch.device(\"cpu\")):\n",
    "\n",
    "    ## Word Embedding.\n",
    "    src_token_embed = WordEmbedding(d_model=d_model, vocab_size=src_vocab_size)\n",
    "    trg_token_embed = WordEmbedding(d_model=d_model, vocab_size=trg_vocab_size)\n",
    "\n",
    "    ## Positional Encoding.\n",
    "    src_pos_embedd = PositionalEncoding(d_model=d_model, max_seq_len=max_seq_len, device=device)\n",
    "    trg_pos_embedd = PositionalEncoding(d_model=d_model, max_seq_len=max_seq_len, device=device)\n",
    "\n",
    "    ## Word Embedding + Positional Encoding.\n",
    "    trg_embed = TransformerEmbedding(word_embedding_layer=trg_token_embed, positional_encoding_layer=trg_pos_embedd, drop_prob=drop_prob)\n",
    "    src_embed = TransformerEmbedding(word_embedding_layer=src_token_embed, positional_encoding_layer=src_pos_embedd, drop_prob=drop_prob)\n",
    "\n",
    "    ## Multi-Head Self Attention.\n",
    "    encoder_attention = MultiHeadAttentionLayer(d_model=d_model, num_heads=num_heads, drop_prob=drop_prob)\n",
    "    decoder_attention = MultiHeadAttentionLayer(d_model=d_model, num_heads=num_heads, drop_prob=drop_prob)\n",
    "    \n",
    "    ## Position-Wise FeedForward.\n",
    "    encoder_position_ff = FeedForwardLayer(d_model, d_ff, drop_prob=drop_prob)\n",
    "    decoder_position_ff = FeedForwardLayer(d_model, d_ff, drop_prob=drop_prob)\n",
    "\n",
    "    ## Add & Norm.\n",
    "    encoder_norm = nn.LayerNorm(d_model, eps=norm_eps)\n",
    "    decoder_norm = nn.LayerNorm(d_model, eps=norm_eps)\n",
    "\n",
    "    ## Encoder Block.\n",
    "    encoder_block = EncoderBlock(self_attention=encoder_attention,\n",
    "                                 ffn=encoder_position_ff,\n",
    "                                 norm=encoder_norm,\n",
    "                                 drop_prob=drop_prob)\n",
    "    \n",
    "    ## Decoder Block\n",
    "    decoder_block = DecoderBlock(self_attention=decoder_attention,\n",
    "                                 cross_attention=decoder_attention,\n",
    "                                 ffn=decoder_position_ff,\n",
    "                                 norm=decoder_norm,\n",
    "                                 drop_prob=drop_prob)\n",
    "\n",
    "    ## Encoder(Encoder Block * Num_layers)\n",
    "    encoder = Encoder(encoder_block=encoder_block, num_layer=num_layer, norm=encoder_norm)\n",
    "\n",
    "    ## Decoder(Decoder Block * Num_layers)\n",
    "    decoder = Decoder(decoder_block=decoder_block, num_layer=num_layer, norm=decoder_norm)\n",
    "\n",
    "    ## Output Layer.\n",
    "    generator = nn.Linear(d_model, trg_vocab_size)\n",
    "\n",
    "    model = Transformer(src_embed=src_embed,\n",
    "                        trg_embed=trg_embed,\n",
    "                        encoder=encoder,\n",
    "                        decoder=decoder,\n",
    "                        generator=generator).to(device)\n",
    "    \n",
    "    model.device = device\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if hasattr(model, 'weight') and model.weight.dim() > 1:\n",
    "        nn.init.kaiming_uniform_(model.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(len(DATASET.src_vocab), len(DATASET.trg_vocab), device=DEVICE, drop_prob=DROP_PROB)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, eps=ADAM_EPS)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, verbose=True, factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=DATASET.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for (src, trg) in tqdm(data_loader, desc=\"train\", leave=False):\n",
    "        src = src.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "        trg_x = trg[:, :-1]\n",
    "        trg_y = trg[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _ = model(src, trg_x)\n",
    "\n",
    "        y_hat = output.contiguous().view(-1, output.shape[-1])\n",
    "        y_gt = trg_y.contiguous().view(-1)\n",
    "        loss = criterion(y_hat, y_gt)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(list(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bleu_score(output, gt, vocab, specials, max_n=4):\n",
    "    def itos(x):\n",
    "        x = list(x.cpu().numpy())\n",
    "        tokens = vocab.lookup_tokens(x)\n",
    "        tokens = list(filter(lambda x: x not in {\"\", \" \", \".\"} and x not in list(specials.keys()), tokens))\n",
    "        return tokens\n",
    "\n",
    "    pred = [out.max(dim=1)[1] for out in output]\n",
    "    pred_str = list(map(itos, pred))\n",
    "    gt_str = list(map(lambda x: [itos(x)], gt))\n",
    "\n",
    "    return  bleu_score(pred_str, gt_str, max_n=max_n) * 100.0\n",
    "\n",
    "\n",
    "def greedy_decode(model, src, max_len, start_symbol, end_symbol):\n",
    "    src = src.to(model.device)\n",
    "    src_mask = model.make_src_mask(src).to(model.device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(model.device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(model.device)\n",
    "        trg_mask = model.make_trg_mask(ys).to(model.device)\n",
    "        src_trg_mask = model.make_src_trg_mask(src, ys).to(model.device)\n",
    "        out = model.decode(ys, memory, trg_mask, src_trg_mask)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == end_symbol:\n",
    "            break\n",
    "        \n",
    "    return ys\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    total_bleu = []\n",
    "    with torch.no_grad():\n",
    "        for (src, trg) in tqdm(data_loader, desc=\"eval\", leave=False):\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "            trg_x = trg[:, :-1]\n",
    "            trg_y = trg[:, 1:]\n",
    "\n",
    "            output, _ = model(src, trg_x)\n",
    "\n",
    "            y_hat = output.contiguous().view(-1, output.shape[-1])\n",
    "            y_gt = trg_y.contiguous().view(-1)\n",
    "            loss = criterion(y_hat, y_gt)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            score = get_bleu_score(output, trg_y, DATASET.trg_vocab, DATASET.SPECIALS)\n",
    "            total_bleu.append(score)\n",
    "\n",
    "    loss_avr = epoch_loss / len(list(data_loader))\n",
    "    bleu_score = sum(total_bleu) / len(total_bleu)\n",
    "\n",
    "    return loss_avr, bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 | train_loss: 5.42834 valid_loss: 4.53360, bleu_scores: 4.31376\n",
      "Predict :  <sos> Ein Mädchen in einem <unk> . <eos>\n",
      "Answer : Ein kleines Mädchen klettert in ein Spielhaus aus Holz . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 | train_loss: 4.46157 valid_loss: 4.10693, bleu_scores: 6.67109\n",
      "Predict :  <sos> Ein Mädchen mit einem Mädchen . <eos>\n",
      "Answer : Ein kleines Mädchen klettert in ein Spielhaus aus Holz . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  61%|██████    | 549/907 [00:13<00:08, 44.60it/s]"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Start\")\n",
    "if not os.path.isdir(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "min_val_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, bleu_scores  = evaluate(model, valid_iter, criterion)\n",
    "\n",
    "    if epoch == 0:\n",
    "        min_val_loss = valid_loss\n",
    "\n",
    "    if epoch > 1:\n",
    "        if valid_loss < min_val_loss:\n",
    "            min_val_loss = valid_loss\n",
    "            ckpt = f\"{SAVE_DIR}/{epoch:04}.pt\"\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'train_loss': train_loss,\n",
    "                        'val_loss' : valid_loss}, ckpt)\n",
    "\n",
    "    if epoch > WARM_UP_STEP:\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "    print(f\"Epoch : {epoch + 1} | train_loss: {train_loss:.5f} valid_loss: {valid_loss:.5f}, bleu_scores: {bleu_scores:.5f}\")\n",
    "    print(\"Predict : \", DATASET.translate(model, \"A little girl climbing into a wooden playhouse .\", greedy_decode))\n",
    "    print(f\"Answer : Ein kleines Mädchen klettert in ein Spielhaus aus Holz . \\n\")\n",
    "\n",
    "test_loss, bleu_scores = evaluate(model, test_iter, criterion)\n",
    "print(f\"test_loss: {test_loss:.5f}\")\n",
    "print(f\"bleu_scores: {bleu_scores:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
