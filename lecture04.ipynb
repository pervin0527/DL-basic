{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function\n",
        "모델의 예측값을  $\\hat{y}$로 표기한다.   \n",
        "model을 학습시킬 때, dataset에 정답 y가 포함되어 있으면, Supervised Learning 이라고 하며, model의 예측값(prediction) $\\hat{y}$ 와 정답 y 간의 오차를 계산한다.  \n",
        "\n",
        "- $\\hat{y}$가 실수 값인 경우 Regression.\n",
        "- Regression의 값은 연속적(continue)이며, 대소관계가 존재한다.\n",
        "- $\\hat{y}$가 정수 값인 경우 Classification.\n",
        "- classification은 값이 비연속적(discrete)이며, 단순히 class에 index를 부여한 것이다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1xsTdrPOYao0QWyE28KaI9PZe578ADbK6\">\n",
        "\n",
        "### One-hot encoding\n",
        "class를 0, 1, 2 ... 등의 정수형태로 표기할 수 있으나, one-hot encoding을 통해 다르게 나타낼 수 있다. 자신에 해당하는 index의 값만 1이고, 그렇지 않은 index는 0이다.\n",
        "\n",
        "[강아지, 고양이, 사람]\n",
        "- 강아지 : (0, 0, 1)\n",
        "- 고양이 : (0, 1, 0)\n",
        "- 사람 : (1, 0, 0)"
      ],
      "metadata": {
        "id": "WpHu2MxdFB6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "학생들의 성적을 예측한다거나, 암이 발생할 확률을 예측한다 등을 regression problem이라 한다.\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1fQwh89Y9DIX0MJQv1EgpfZzuiL1Vyv3N\">\n",
        "- dataset을 구성하는 row는 각각의 data sample을 말함.(예를 들어 학생1, 학생2, 학생3, ... 학생N)\n",
        "- column은 data의 attribute(feature)로 공부시간, 등하교 소요시간, 다니는 학원의 수, 수면 시간 등.\n",
        "- Y 벡터는 각각 학생들의 성적. 정답에 해당하며 model의 prediction과 비교한다.\n",
        "\n",
        "### 1개의 데이터를 입력할 때.\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1k9R20EQsQbd0LrhTyp33L--ypIE-aGQh\">\n",
        "\n",
        "- 학생 1에 대한 데이터들을 입력.(X와 Y로 구성)\n",
        "- 구성한 Layer들을 거치게 되는데, 마지막 layer에서는 Activation function을 사용하지 않으며 1개의 뉴런으로 구성.(예측값 1개를 출력해야 하니까).\n",
        "- 출력한 값이 $\\hat{y}$. y-prediction이되어, 정답값 y와의 오차를 계산한다.\n",
        "- Sqared Error : $ J = (y-\\hat{y})^2$ 를 계산하며, 두 값의 차이가 작을수록 loss 값이 작다."
      ],
      "metadata": {
        "id": "B5V52jDXIPhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mini batch 단위로 입력할 때.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1YHlQlRMG3g3vHQgkKmq_PAxCBm4g6nSI\">\n",
        "\n",
        "- 입력 데이터 X는 l<sub>i</sub> 개의 feature를 가진 row vector가 N개 쌓여있는 Matrix.\n",
        "- 학생1, 학생2, ... 들의 데이터가 batch size N만큼 존재.\n",
        "- 데이터 row 각각에 대한 prediction value를 구하고, column vector $\\hat{Y}$로 나타낸다.\n",
        "- 정답값 y들이 vector로 묶인 column vector Y와 비교를 진행한다.\n",
        "- batch-size N개에 대한 비교이므로 이에 대한 평균을 구함. Mean Squared Error.\n",
        "- 평균을 구하는 이유는 N개의 y와 y-prediction 간의 차이를 평균 낸 것이 바로 loss 값."
      ],
      "metadata": {
        "id": "xCVejKnbLOuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification\n",
        "Regression이 시험 점수를 예측하는 것이라면, Binary classification은 시험에 합격하거나 불합격하는 것을 분류한다. 따라서 y값이 0 또는 1로 구성되어 있다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1EHrRo6N85cXcgb4Loz4U3dijtbXUW5Sx\">\n",
        "\n"
      ],
      "metadata": {
        "id": "_nDCkgZ6UFBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Cross Entropy\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1evwtFpgWjbgF6EDdolxsf6nyTj5dkQ6H\">\n",
        "\n",
        "- y = 1 인 경우, $(1-y)log(1-\\hat{y}) = 0$이 된다.\n",
        "- 따라서 $-log(\\hat{y})$ 항만 남게 된다.\n",
        "- -log 함수는 입력이 1에 가까워질수록 출력이 0에 수렴하고, 입력이 0에 가까워질수록 출력이 무한히 발산한다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1KSTtR1PKAnQ1ZGlaxxe_18tCLtJT3zNJ\">\n",
        "\n",
        "- y = 0 인경우, $ylog(\\hat{y})$ 항이 0이 된다.  \n",
        "- 따라서 $-log(1-\\hat{y})$ 항만 남게 된다.\n",
        "- $-log(1-\\hat{y})$ 함수는 입력값이 1에 가까워질수록 함수값은 무한히 발산. 입력값이 0에 가까워질수록 함수값은 0에 수렴한다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=11Tqme2ytnSfX3I_aArHoYUJQt3MzltOy\">"
      ],
      "metadata": {
        "id": "2IuATm6hU0fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=1rohBqwsj2ujkCIYlCSoJMgRjQ2-d85Ye\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1UElDXIkw1Y3HTgrariXNBheUCqvuV2A8\">\n",
        "\n",
        "- 마지막 layer의 출력값 형태가 벡터가 아닌 하나의 값이므로 1개 뉴런으로 구성되어야 함.\n",
        "- Binary Cross Entropy는 결국 $\\hat{y}$의 값이 0 ~ 1 범위에서 어떤 값인지가 중요하므로, 마지막 layer를 통해 얻은 logit이 probability가 되어야 함.\n",
        "- 따라서 마지막 layer의 activation function은 sigmoid가 된다."
      ],
      "metadata": {
        "id": "obQytjB4WYEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class Classification\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1lr--YUxgthwVJesJGVUClFvOH3db265I\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1_cgNx8FUJ2EkJtbVj2APg8pSf9I1LG2X\">\n",
        "\n",
        "multi-class classification은 K개의 class에 대한 분류를 진행한다.  \n",
        "class 값을 단순히 정수의 형태로 y로 사용할 수 있지만, 보통은 One-hot encoding을 적용하여 사용한다.\n",
        "\n",
        "one-hot encoding을 적용하면 정수값 y가 class index에 해당하는 값만 1이고 나머지는 0인 row vector로 변환된다.  \n",
        "따라서, minibatch 형태로 입력이 진행되면 N개의 K차원의 row vector로 구성된 matrix가 입력된다."
      ],
      "metadata": {
        "id": "PPAgmCMbdfm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical Cross Entropy\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1s2i-DLyj7hyAJIYFXVQtKnqR18bVqQ4_\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1RAKAG5SNIqS7REHgqW3XhgNhtulubyBJ\">\n",
        "\n",
        "- 입력 y의 형태가 one-hot encoding을 통해 row vector 형태임.\n",
        "- 마지막 layer는 activation function이 없으며, K차원의 row logit vector를 출력한다.\n",
        "- 이를 softmax 함수를 통해 K차원의 row probability vector를 구할 수 있다.\n",
        "- 따라서 y row vector와 y-pred row vector를 입력으로 받는다."
      ],
      "metadata": {
        "id": "CYUw39PGe97q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=1ptmcJ3nG5Hizy_CSS0eXi41f71fExjiH\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1OWpDF4PlSOnyGfLBQYI3V8RB8FW9okp2\">\n",
        "\n",
        "- 마찬가지로 minibatch로 입력이 되면, batch size로 나눗셈을 해서 평균을 구함.\n",
        "- 평균을 구하는 이유는 N개의 y와 y-prediction 간의 차이를 평균 낸 것이 바로 loss 값."
      ],
      "metadata": {
        "id": "bEKdA0T5gdd1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-drT0QiP3UXi",
        "outputId": "a2abe8c1-845f-4e5a-93f2-f92dd77b1aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 5) (5,) (1,)\n",
            "X : (8, 5) \n",
            " [[-1.4930753   1.3345237  -0.91198444 -0.50894606 -0.6075962 ]\n",
            " [ 1.3073512  -1.7033762  -0.72343546  1.8242912   1.7353021 ]\n",
            " [ 0.361023    0.8645596  -0.19657306 -2.360987    0.40157598]\n",
            " [ 3.1990354   1.7235271   0.8566709  -0.70381325  0.1907561 ]\n",
            " [-0.12984852 -0.82439935 -0.46054646  2.1541405   1.5393333 ]\n",
            " [-0.4477212  -1.7297351   1.2450572   0.9209218  -0.280761  ]\n",
            " [-0.23906367 -0.4622468   0.8814835  -1.2936985  -2.3412263 ]\n",
            " [ 0.19042341  0.33515307  1.7220889  -2.3718932   0.4755156 ]]\n",
            "Y : (8,) \n",
            " [ 3.3662534 21.703968   4.064355  17.35463   23.152943  12.107862\n",
            " -5.400033   8.917002 ]\n"
          ]
        }
      ],
      "source": [
        "## Regression dataset 만들기\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "N, n_feature = 8, 5\n",
        "target_weights = tf.constant([1,2,3,4,5], dtype=tf.float32)\n",
        "target_bias = tf.constant([10], dtype=tf.float32)\n",
        "\n",
        "X = tf.random.normal(mean=0, stddev=1, shape=(N, n_feature))\n",
        "print(X.shape, target_weights.shape, target_bias.shape)\n",
        "\n",
        "Y = tf.reduce_sum(X * target_weights, axis=1) + target_bias\n",
        "print(f\"X : {X.shape} \\n {X}\")\n",
        "print(f\"Y : {Y.shape} \\n {Y}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Classification\n",
        "\n",
        "N, n_feature = 8, 5\n",
        "target_weights = tf.constant([1,2,3,4,5], dtype=tf.float32)\n",
        "target_bias = tf.constant([10], dtype=tf.float32)\n",
        "\n",
        "X = tf.random.normal(mean=0, stddev=1, shape=(N, n_feature))\n",
        "print(X.shape, target_weights.shape, target_bias.shape)\n",
        "\n",
        "Y = tf.reduce_sum(X * target_weights, axis=1) + target_bias\n",
        "Y = tf.cast(Y > 5, tf.int32)\n",
        "\n",
        "print(f\"X : {X.shape} \\n {X}\")\n",
        "print(f\"Y : {Y.shape} \\n {Y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YwrSLVkkJUl",
        "outputId": "4888e486-298b-40da-c575-7031547297a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 5) (5,) (1,)\n",
            "X : (8, 5) \n",
            " [[ 0.7338259  -2.6979623   0.42889762 -0.11676811 -0.8810875 ]\n",
            " [-0.7275572   0.7166105  -0.67742765 -0.05018659  0.3451025 ]\n",
            " [-0.55070496  0.11507922 -0.92022514  0.44090533  0.02984732]\n",
            " [ 0.55044484 -1.6003379  -1.3094425   0.5353948   0.7739458 ]\n",
            " [-0.37567943 -0.41217077  0.34747136  0.59330016 -1.2117082 ]\n",
            " [-0.5236824  -0.9172348  -0.6039777  -0.00440334 -0.09082987]\n",
            " [ 0.31754997 -0.4484668   1.0320437   0.0755452  -0.21272524]\n",
            " [ 0.60493803 -0.4409681   0.13188781 -2.0074198  -0.5371016 ]]\n",
            "Y : (8,) \n",
            " [0 1 1 1 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multi-class classification\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "N, n_features = 5, 2\n",
        "n_class = 5\n",
        "\n",
        "X = tf.zeros(shape=(0, n_features))\n",
        "Y = tf.zeros(shape=(0, 1), dtype=tf.int32)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "for class_idx in range(n_class):\n",
        "    center = tf.random.uniform(minval=-15, maxval=15, shape=(2, ))\n",
        "    # ax.scatter(center[0], center[1])\n",
        "\n",
        "    x1 = center[0] + tf.random.normal(shape=(N, 1))\n",
        "    x2 = center[1] + tf.random.normal(shape=(N, 1))\n",
        "\n",
        "    x = tf.concat((x1, x2), axis=1)\n",
        "    y = class_idx * tf.ones(shape=(N, 1), dtype=tf.int32)\n",
        "    \n",
        "    ax.scatter(x[:, 0].numpy(), x[:, 1].numpy(), alpha=0.3)\n",
        "\n",
        "    X = tf.concat((X, x), axis=0)\n",
        "    Y = tf.concat((Y, y), axis=0)\n",
        "\n",
        "print(f\"X : {X.shape} \\n {X}\")\n",
        "print(f\"Y : {Y.shape} \\n {Y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ohnJJIv7mcbu",
        "outputId": "8ee81460-1a19-4995-9d9b-50c3ec81f8bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X : (25, 2) \n",
            " [[ 11.046533  -11.880659 ]\n",
            " [ 10.555666  -12.21824  ]\n",
            " [ 11.096873  -10.651361 ]\n",
            " [ 10.912307  -11.311633 ]\n",
            " [ 11.959689  -12.779601 ]\n",
            " [ -7.282735   10.901099 ]\n",
            " [-10.65052     9.435011 ]\n",
            " [-11.123463    9.558871 ]\n",
            " [-10.160439    7.626721 ]\n",
            " [ -8.595537    6.7262373]\n",
            " [  4.3915453  -4.4666266]\n",
            " [  1.3293138  -5.92636  ]\n",
            " [  2.3212798  -5.0178766]\n",
            " [  1.9159001  -3.0308697]\n",
            " [  1.2414168  -3.6302023]\n",
            " [  4.607026    3.8518577]\n",
            " [  5.480746    2.7388244]\n",
            " [  7.5838137   2.9340532]\n",
            " [  5.515619    1.162799 ]\n",
            " [  5.1609316   1.657093 ]\n",
            " [-12.572742    2.991971 ]\n",
            " [-12.094378    3.22445  ]\n",
            " [-10.9322405   2.9442923]\n",
            " [-11.483671    3.4578552]\n",
            " [-11.418629    3.422646 ]]\n",
            "Y : (25, 1) \n",
            " [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multi-class classification + one-hot encoding\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "N, n_features = 5, 2\n",
        "n_class = 5\n",
        "\n",
        "X = tf.zeros(shape=(0, n_features))\n",
        "Y = tf.zeros(shape=(0, ), dtype=tf.int32)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "for class_idx in range(n_class):\n",
        "    center = tf.random.uniform(minval=-15, maxval=15, shape=(2, ))\n",
        "    # ax.scatter(center[0], center[1])\n",
        "\n",
        "    x1 = center[0] + tf.random.normal(shape=(N, 1))\n",
        "    x2 = center[1] + tf.random.normal(shape=(N, 1))\n",
        "\n",
        "    x = tf.concat((x1, x2), axis=1)\n",
        "    y = class_idx * tf.ones(shape=(N, ), dtype=tf.int32)\n",
        "    \n",
        "    ax.scatter(x[:, 0].numpy(), x[:, 1].numpy(), alpha=0.3)\n",
        "\n",
        "    X = tf.concat((X, x), axis=0)\n",
        "    Y = tf.concat((Y, y), axis=0)\n",
        "\n",
        "Y = tf.one_hot(Y, depth=n_class, dtype=tf.int32)\n",
        "print(f\"X : {X.shape} \\n {X}\")\n",
        "print(f\"Y : {Y.shape} \\n {Y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l7O-CG0Dn22m",
        "outputId": "8be80521-dbac-4b9f-f11a-bae6133cb34c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X : (25, 2) \n",
            " [[ -6.4813657   3.0444288]\n",
            " [ -5.9439416   2.1291192]\n",
            " [ -4.4869285   3.0390615]\n",
            " [ -4.964936    3.9632192]\n",
            " [ -7.049577    3.894293 ]\n",
            " [  8.166056    5.5032587]\n",
            " [  8.480863    5.933994 ]\n",
            " [ 10.161367    6.3658223]\n",
            " [  9.7490835   5.290667 ]\n",
            " [ 11.508082    7.013811 ]\n",
            " [-12.852167   -8.827892 ]\n",
            " [-14.118063   -7.630522 ]\n",
            " [-13.073804   -7.8005867]\n",
            " [-11.93514    -9.246545 ]\n",
            " [-10.588137  -10.929508 ]\n",
            " [ 10.994567    4.757876 ]\n",
            " [  9.555524    3.0564766]\n",
            " [  8.870576    3.070953 ]\n",
            " [ 12.125554    3.1914067]\n",
            " [ 10.55345     3.7620182]\n",
            " [ 12.610445   -1.8685951]\n",
            " [ 13.786278   -3.013658 ]\n",
            " [ 14.673464   -2.7544942]\n",
            " [ 11.843006   -1.1287723]\n",
            " [ 13.614786   -2.419723 ]]\n",
            "Y : (25, 5) \n",
            " [[1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using dataset object\n",
        "\n",
        "N, n_feature = 100, 5\n",
        "batch_size = 32\n",
        "\n",
        "target_weights = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)\n",
        "target_bias = tf.constant([10], dtype=tf.float32)\n",
        "\n",
        "X = tf.random.normal(mean=0, stddev=1, shape=(N, n_feature))\n",
        "Y = tf.reduce_sum(X * target_weights, axis=1) + target_bias\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "for x, y in dataset:\n",
        "    print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAk503wkpmAX",
        "outputId": "401d582b-0db3-4692-9dfa-c5b948368981"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 5) (32,)\n",
            "(32, 5) (32,)\n",
            "(32, 5) (32,)\n",
            "(4, 5) (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mean Squared Error\n",
        "\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "batch_size = 32\n",
        "predictions = tf.random.normal(shape=(batch_size, 1))\n",
        "labels = tf.random.normal(shape=(batch_size, 1))\n",
        "\n",
        "mse = loss_object(labels, predictions)\n",
        "mse_man = tf.reduce_mean(tf.math.pow(labels - predictions, 2))\n",
        "print(f\"MSE tensorflow : {mse}\")\n",
        "print(f\"MSE manual : {mse_man}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JrBuQ0vrKE3",
        "outputId": "70827130-0eb8-4ba5-f20c-9d96858b9c4d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE tensorflow : 2.59311580657959\n",
            "MSE manual : 2.59311580657959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mean Squared Error with model\n",
        "\n",
        "batch_size=32\n",
        "N, n_features = 100, 0\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "Y = tf.random.normal(shape=(N, 1))\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "dense = tf.keras.layers.Dense(units=1, activation=\"linear\")\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "for x, y in dataset:\n",
        "    predictions = dense(x)\n",
        "    loss = loss_object(y, predictions)\n",
        "    print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYC0hYPHuIMi",
        "outputId": "a3454f56-5c4a-4290-d69d-6b93b87497e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.67088\n",
            "3.5767403\n",
            "2.0359492\n",
            "5.0128183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Cross Entropy\n",
        "batch_size = 10\n",
        "n_class = 2\n",
        "\n",
        "predictions = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1, dtype=tf.float32)\n",
        "labels = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=n_class, dtype=tf.int32)\n",
        "\n",
        "print(predictions)\n",
        "print(labels)\n",
        "\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
        "loss = loss_object(labels, predictions)\n",
        "\n",
        "labels = tf.cast(labels, tf.float32)\n",
        "bce_man = -(labels*tf.math.log(predictions) + (1 - labels) * tf.math.log(1 - predictions))\n",
        "bce_man = tf.reduce_mean(bce_man)\n",
        "\n",
        "print(f\"BCE : {loss}\")\n",
        "print(f\"BCE man : {bce_man}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsVcwo7I1kh9",
        "outputId": "0797b102-fa0a-4e18-bad3-1dad160820ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.6767442 ]\n",
            " [0.7782978 ]\n",
            " [0.9923327 ]\n",
            " [0.30122685]\n",
            " [0.04045272]\n",
            " [0.2641797 ]\n",
            " [0.6056509 ]\n",
            " [0.35480618]\n",
            " [0.00303745]\n",
            " [0.9727193 ]], shape=(10, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]], shape=(10, 1), dtype=int32)\n",
            "BCE : 0.9793401956558228\n",
            "BCE man : 0.9793416857719421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Cross Entropy with model\n",
        "\n",
        "N, n_feature = 100, 5\n",
        "batch_size = 32\n",
        "\n",
        "target_weights = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)\n",
        "target_bias = tf.constant([0], dtype=tf.float32)\n",
        "\n",
        "X = tf.random.normal(mean=0, stddev=1, shape=(N, n_feature))\n",
        "Y = tf.reduce_sum(target_weights * X, axis=1) + target_bias\n",
        "Y = tf.cast(Y > 5, tf.int32)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "dense = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "for x, y in dataset:\n",
        "    predictions = dense(x)\n",
        "    loss = loss_object(y, predictions)\n",
        "    print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uidA-cQK6uYJ",
        "outputId": "92243c97-b6ed-4023-c802-8d38d28b831b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8150563\n",
            "0.9019711\n",
            "0.9352723\n",
            "1.0338901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Sparse Categorical Cross Entropy\n",
        "\n",
        "batch_size, n_class = 16, 5\n",
        "\n",
        "predictions = tf.random.uniform(shape=(batch_size, n_class),\n",
        "                                minval=0, maxval=1, \n",
        "                                dtype=tf.float32)\n",
        "\n",
        "pred_sum = tf.reshape(tf.reduce_sum(predictions, axis=1), (-1, 1))\n",
        "predictions = predictions / pred_sum\n",
        "\n",
        "labels = tf.random.uniform(shape=(batch_size, ),\n",
        "                           minval=0, maxval=n_class,\n",
        "                           dtype=tf.int32)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "loss = loss_object(labels, predictions)\n",
        "\n",
        "ce = 0\n",
        "for label, prediction in zip(labels, predictions):\n",
        "    ce += -tf.math.log(prediction[label])\n",
        "\n",
        "ce /= batch_size\n",
        "print(ce.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgelWKQ3DauU",
        "outputId": "2778ebf0-b289-4d84-cc3f-a7040fde5605"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9584482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N, n_features = 100, 2\n",
        "n_class = 5\n",
        "\n",
        "X = tf.zeros(shape=(0, n_features))\n",
        "Y = tf.zeros(shape=(0, 1), dtype=tf.int32)\n",
        "\n",
        "for class_idx in range(n_class):\n",
        "    center = tf.random.uniform(minval=-15, maxval=15, shape=(2, ))\n",
        "\n",
        "    x1 = center[0] + tf.random.normal(shape=(N, 1))\n",
        "    x2 = center[1] + tf.random.normal(shape=(N, 1))\n",
        "\n",
        "    x = tf.concat((x1, x2), axis=1)\n",
        "    y = class_idx * tf.ones(shape=(N, 1), dtype=tf.int32)\n",
        "    \n",
        "    X = tf.concat((X, x), axis=0)\n",
        "    Y = tf.concat((Y, y), axis=0)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "dense = tf.keras.layers.Dense(units=n_class, activation=\"softmax\")\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "for x, y in dataset:\n",
        "    predictions = dense(x)\n",
        "    loss = loss_object(y, predictions)\n",
        "    print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4uBBY1VEp_j",
        "outputId": "590fa72c-cc9b-4e2a-e744-c5038a01e09d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.592183\n",
            "5.588833\n",
            "5.625864\n",
            "5.6471267\n",
            "5.7249603\n",
            "5.817146\n",
            "4.8429933\n",
            "4.6092863\n",
            "4.79323\n",
            "4.396792\n",
            "4.2065177\n",
            "4.49392\n",
            "1.982167\n",
            "0.076511085\n",
            "0.06899251\n",
            "0.087938726\n",
            "0.08928342\n",
            "0.07531454\n",
            "0.61767024\n",
            "2.2443533\n",
            "1.9303048\n",
            "2.1251311\n",
            "1.7862756\n",
            "2.222279\n",
            "1.765198\n",
            "0.01504786\n",
            "0.010954406\n",
            "0.011267267\n",
            "0.012008047\n",
            "0.021366498\n",
            "0.0063185967\n",
            "0.008993806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Categorical Cross Entropy\n",
        "\n",
        "batch_size, n_class =16, 5\n",
        "\n",
        "predictions = tf.random.uniform(shape=(batch_size, n_class),\n",
        "                                minval=0, maxval=1,\n",
        "                                dtype=tf.float32)\n",
        "\n",
        "pred_sum = tf.reduce_sum(predictions, axis=1) ## row 단위로 더함. 16\n",
        "pred_sum = tf.reshape(pred_sum, (-1, 1)) ## 16, 1\n",
        "predictions = predictions / pred_sum ## row 단위로 합을 나눠주면, row별로 총 합이 1인 prediction으로 만들어짐.\n",
        "\n",
        "labels = tf.random.uniform(shape=(batch_size, ),\n",
        "                           minval=0, maxval=n_class,\n",
        "                           dtype=tf.int32)\n",
        "labels = tf.one_hot(labels, n_class)\n",
        "\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "loss = loss_object(labels, predictions)\n",
        "\n",
        "print(\"CCE tensorflow : \", loss.numpy())\n",
        "\n",
        "tmp = tf.reduce_mean(tf.reduce_sum(-labels * tf.math.log(predictions), axis=1))\n",
        "print(\"CCE man : \", tmp.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3IVF2saQcNu",
        "outputId": "cbf40b63-39fd-456e-9c46-2868ddb87f8f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE tensorflow :  2.267531\n",
            "CCE man :  2.267531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N, n_feature = 8, 2\n",
        "n_class = 5\n",
        "\n",
        "X = tf.zeros(shape=(0, n_feature))\n",
        "Y = tf.zeros(shape=(0, ), dtype=tf.int32)\n",
        "\n",
        "for class_idx in range(n_class):\n",
        "    center = tf.random.uniform(minval=-15, maxval=15, shape=(2, ))\n",
        "    \n",
        "    x1 = center[0] + tf.random.normal(shape=(N, 1))\n",
        "    x2 = center[1] + tf.random.normal(shape=(N, 1))\n",
        "\n",
        "    x = tf.concat((x1, x2), axis=1)\n",
        "    y = class_idx * tf.ones(shape=(N, ), dtype=tf.int32)\n",
        "\n",
        "    X = tf.concat((X, x), axis=0)\n",
        "    Y = tf.concat((Y, y), axis=0)\n",
        "\n",
        "Y = tf.one_hot(Y, depth=n_class, dtype=tf.int32)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "model = tf.keras.layers.Dense(units=n_class, activation=\"softmax\")\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "for x, y in dataset:\n",
        "    predictions = model(x)\n",
        "    loss = loss_object(y, predictions)\n",
        "    print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFfFcZaDR8lV",
        "outputId": "6e533147-4160-436d-b75f-58f7848c66dd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3614678\n",
            "4.386647\n",
            "5.8316183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, n_class =16, 5\n",
        "\n",
        "predictions = tf.random.uniform(shape=(batch_size, n_class),\n",
        "                                minval=0, maxval=1,\n",
        "                                dtype=tf.float32) ## 0 ~ 1 사이 값.\n",
        "print(predictions[0])\n",
        "\n",
        "pred_sum = tf.reduce_sum(predictions, axis=1) ## row 단위로 더함. 16\n",
        "print(pred_sum[0])\n",
        "\n",
        "\n",
        "pred_sum = tf.reshape(pred_sum, (-1, 1)) ## 16, 1\n",
        "print(pred_sum[0])\n",
        "\n",
        "\n",
        "predictions = predictions / pred_sum ## row 단위로 합을 나눠주면, row별로 총 합이 1인 prediction으로 만들어짐.\n",
        "print(predictions[0])\n",
        "print(tf.reduce_sum(predictions[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo6B6h0uVSgU",
        "outputId": "01752335-c255-4fd2-e24e-d707b8c0a5ea"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.920025   0.8870747  0.18793738 0.78301775 0.29404616], shape=(5,), dtype=float32)\n",
            "tf.Tensor(3.0721009, shape=(), dtype=float32)\n",
            "tf.Tensor([3.0721009], shape=(1,), dtype=float32)\n",
            "tf.Tensor([0.29947746 0.2887518  0.06117552 0.25488022 0.09571501], shape=(5,), dtype=float32)\n",
            "tf.Tensor(1.0000001, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKiLmTkMV2R5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}