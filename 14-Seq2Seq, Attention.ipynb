{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14-Seq2Seq, Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.Define Vocab](#1)\n",
    "\n",
    "[2.Data Preprocessing](#2)\n",
    "\n",
    "[3.Load & Read Dataset](#3)\n",
    "\n",
    "[4.Sequence to Sequence](#4)\n",
    " - [4-1.Encoder](#4-1)\n",
    " - [4-2.Decoder](#4-2)\n",
    " - [4-3.Training](#4-3)\n",
    " - [4-4.Evaluate](#4-4)\n",
    "\n",
    "[5.Attention Decoder](#5)\n",
    " - [5-1.Attention with Decoder](#5-1)\n",
    " - [5-2.Training](#5-2)\n",
    " - [5-3.Evaluate](#5-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from io import open\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1.Define Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    \n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    ## MAX_LENGTH를 초과하는지, eng_prefixes에 해당하는 것으로 영문장이 시작되는지 검사. True or False를 반환.\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    ## True를 반환 받으면 리스트에 추가하고, False를 받으면 리스트에 추가하지 않는다.\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3.Load & Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(f'/home/pervinco/Datasets/en-fr/data/{lang1}-{lang2}.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines] ## Unicode -> Ascii + (fr_sentence, en_sentence)\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['il ne se trouve pas en ville', 'he s out of town']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4.Sequence to Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-1\"></a>\n",
    "### 4-1.Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, (hidden, cell) = self.lstm(output, hidden)  # LSTM은 hidden과 cell state를 반환\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device=device),  # hidden state 초기화\n",
    "                torch.zeros(1, 1, self.hidden_dim, device=device))  # cell state 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2\"></a>\n",
    "### 4-2.Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, (hidden, cell) = self.lstm(output, hidden)  # LSTM 사용으로 hidden과 cell 상태 업데이트\n",
    "        output = self.softmax(self.out(output[0]))  # Softmax 활성화 함수 사용\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),  # hidden state 초기화\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device))  # cell state 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-3\"></a>\n",
    "### 4-3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoder\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        # LSTM의 encoder_hidden은 (hidden state, cell state) 튜플\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "    decoder_hidden = encoder_hidden  # Encoder의 마지막 hidden state를 Decoder의 초기 hidden state로 사용\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: 다음 입력으로 목표(target) 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di].unsqueeze(0)  # Teacher forcing 사용\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing 없음: 자신의 예측을 다음 입력으로 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1) ## 디코더가 출력한 결과 중에서 가장 높은 확률을 가진 원소 하나를 선택\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)  # 입력을 위해 squeeze 후 detach\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    주어진 문장을 공백을 기준으로 단어로 분리한 뒤, 각 단어에 해당하는 인덱스를 lang의 word2index 딕셔너리를 사용하여 찾아낸다. \n",
    "    결과적으로 문장을 인덱스의 배열로 변환.\n",
    "    \"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    문장을 인덱스 배열로 변환한 후, 특별한 토큰인 EOS_token (End Of Sentence 토큰, 문장의 끝을 나타냄)을 배열에 추가.\n",
    "    배열을 Tensor로 변환.\n",
    "    \"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    \n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f\"Iter : {iter}, Loss : {print_loss_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 5000, Loss : 3.0969\n",
      "Iter : 10000, Loss : 2.6752\n",
      "Iter : 15000, Loss : 2.4425\n",
      "Iter : 20000, Loss : 2.1947\n",
      "Iter : 25000, Loss : 1.9700\n",
      "Iter : 30000, Loss : 1.7812\n",
      "Iter : 35000, Loss : 1.6168\n",
      "Iter : 40000, Loss : 1.4359\n",
      "Iter : 45000, Loss : 1.3210\n",
      "Iter : 50000, Loss : 1.2174\n",
      "Iter : 55000, Loss : 1.1165\n",
      "Iter : 60000, Loss : 1.0301\n",
      "Iter : 65000, Loss : 0.9261\n",
      "Iter : 70000, Loss : 0.8489\n",
      "Iter : 75000, Loss : 0.7715\n",
      "Iter : 80000, Loss : 0.6923\n",
      "Iter : 85000, Loss : 0.6457\n",
      "Iter : 90000, Loss : 0.6061\n",
      "Iter : 95000, Loss : 0.5434\n",
      "Iter : 100000, Loss : 0.4974\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(HIDDEN_DIM, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 100000, print_every=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-4\"></a>\n",
    "### 4-4.Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden  # LSTM의 경우 (hidden, cell) 튜플 사용\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous attendons la publication de son ouvrage\n",
      "= we are expecting the publication of his book\n",
      "< we are expecting the of his book <EOS>\n",
      "\n",
      "> je suis trop fatigue pour penser\n",
      "= i m too tired to think\n",
      "< i m too tired to think <EOS>\n",
      "\n",
      "> vous n etes pas autorise a manger ceux la\n",
      "= you re not allowed to eat those\n",
      "< you re not allowed to eat those <EOS>\n",
      "\n",
      "> nous sommes jalouses\n",
      "= we re jealous\n",
      "< we re jealous <EOS>\n",
      "\n",
      "> je suis tres serieuse\n",
      "= i m very serious\n",
      "< i m very serious <EOS>\n",
      "\n",
      "> elle a les pieds en dedans\n",
      "= she is pigeon toed\n",
      "< she is walking in chinese <EOS>\n",
      "\n",
      "> je suis tres gros\n",
      "= i m very fat\n",
      "< i m very fat <EOS>\n",
      "\n",
      "> elles sont mignonnes\n",
      "= they re cute\n",
      "< they re cute <EOS>\n",
      "\n",
      "> nous sommes sous son commandement\n",
      "= we are under his command\n",
      "< we are under his his <EOS>\n",
      "\n",
      "> vous etes precisement l homme que je veux voir\n",
      "= you are the very man i want to see\n",
      "< you re the the man i want <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5-1\"></a>\n",
    "## 5-1.Attention with Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.attn = nn.Linear(self.hidden_dim * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim)  # GRU 대신 LSTM 사용\n",
    "        self.out = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # Softmax 대신 LogSoftmax 사용\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)  # attention score를 계산하고, attention dist를 구함.\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0)) # attention value\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)  # LSTM 사용\n",
    "\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device=device),  # hidden state 초기화\n",
    "                torch.zeros(1, 1, self.hidden_dim, device=device))  # cell state 초기화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5-2\"></a>\n",
    "## 5-2.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_dim, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])  # .unsqueeze(0) 제거\n",
    "            decoder_input = target_tensor[di].unsqueeze(0)  # target_tensor[di]가 스칼라 값인 경우\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])  # .unsqueeze(0) 제거\n",
    "            if decoder_input.item() == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 5000, Loss : 3.0957\n",
      "Iter : 10000, Loss : 2.6877\n",
      "Iter : 15000, Loss : 2.3743\n",
      "Iter : 20000, Loss : 2.1446\n",
      "Iter : 25000, Loss : 1.8948\n",
      "Iter : 30000, Loss : 1.7686\n",
      "Iter : 35000, Loss : 1.6334\n",
      "Iter : 40000, Loss : 1.4668\n",
      "Iter : 45000, Loss : 1.3585\n",
      "Iter : 50000, Loss : 1.2681\n",
      "Iter : 55000, Loss : 1.1454\n",
      "Iter : 60000, Loss : 1.0421\n",
      "Iter : 65000, Loss : 0.9802\n",
      "Iter : 70000, Loss : 0.9094\n",
      "Iter : 75000, Loss : 0.8256\n",
      "Iter : 80000, Loss : 0.7575\n",
      "Iter : 85000, Loss : 0.7183\n",
      "Iter : 90000, Loss : 0.6538\n",
      "Iter : 95000, Loss : 0.6049\n",
      "Iter : 100000, Loss : 0.5695\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, HIDDEN_DIM).to(device)\n",
    "decoder = AttnDecoder(HIDDEN_DIM, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 100000, print_every=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5-3\"></a>\n",
    "### 5-3.Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_dim, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, _ = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je me rejouis de te voir heureux\n",
      "= i m glad to see you re happy\n",
      "< i m glad to see you re happy <EOS>\n",
      "\n",
      "> c est un scientifique de niveau international\n",
      "= he s a world class scientist\n",
      "< he s a strange class <EOS>\n",
      "\n",
      "> il revasse toujours\n",
      "= he is always day dreaming\n",
      "< he is always day <EOS>\n",
      "\n",
      "> nous n y sommes pas habitues\n",
      "= we re not used to it\n",
      "< we re not used to it <EOS>\n",
      "\n",
      "> nous sommes en guerre\n",
      "= we are at war\n",
      "< we re at war <EOS>\n",
      "\n",
      "> tu es vraiment egoiste\n",
      "= you re really selfish\n",
      "< you re really selfish <EOS>\n",
      "\n",
      "> tu es trop vieux pour moi\n",
      "= you re too old for me\n",
      "< you re too old for me <EOS>\n",
      "\n",
      "> vous etes bizarres\n",
      "= you re weird\n",
      "< you re weird <EOS>\n",
      "\n",
      "> il est mechant\n",
      "= he is nasty\n",
      "< he is lazy <EOS>\n",
      "\n",
      "> elles sont autosuffisantes\n",
      "= they re self sufficient\n",
      "< they re self sufficient <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
