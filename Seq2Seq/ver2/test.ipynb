{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/DL/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for data_sample in data_iter:\n",
    "        yield tokenizer(data_sample[0])\n",
    "        yield tokenizer(data_sample[1])\n",
    "\n",
    "\n",
    "def build_vocab(special_tokens=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]):\n",
    "    tokenize_de = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "    tokenize_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "    train_iter = Multi30k(split='train', language_pair=('de', 'en'))\n",
    "    vocab_de = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_de), specials=special_tokens)\n",
    "    vocab_en = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_en), specials=special_tokens)\n",
    "    \n",
    "    vocab_de.set_default_index(vocab_de[\"<unk>\"])\n",
    "    vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
    "\n",
    "    return vocab_de, vocab_en, tokenize_de, tokenize_en\n",
    "\n",
    "\n",
    "def collate_fn(batch, vocab_de, vocab_en, tokenizer_de, tokenizer_en):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for (src_item, trg_item) in batch:\n",
    "        src_tensor = torch.tensor([vocab_de[token] for token in tokenizer_de(src_item)], dtype=torch.long)\n",
    "        trg_tensor = torch.tensor([vocab_en[token] for token in tokenizer_en(trg_item)], dtype=torch.long)\n",
    "        \n",
    "        src_batch.append(torch.cat([torch.tensor([vocab_de['<bos>']]), src_tensor, torch.tensor([vocab_de['<eos>']])], dim=0))\n",
    "        trg_batch.append(torch.cat([torch.tensor([vocab_en['<bos>']]), trg_tensor, torch.tensor([vocab_en['<eos>']])], dim=0))\n",
    "\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=vocab_de['<pad>'])\n",
    "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=vocab_en['<pad>'])\n",
    "\n",
    "    return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 18:09:39.903986: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-25 18:09:39.993337: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-25 18:09:40.298871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-05-25 18:09:40.298936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-05-25 18:09:40.298941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-05-25 18:09:40.648171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-25 18:09:40.648644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-25 18:09:40.648708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/pervinco/.local/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 32]) torch.Size([24, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TRG_LANGUAGE = 'en'\n",
    "\n",
    "vocab_de, vocab_en, tokenize_de, tokenize_en = build_vocab()\n",
    "dataset = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=lambda batch: collate_fn(batch, vocab_de, vocab_en, tokenize_de, tokenize_en))\n",
    "\n",
    "for src, tgt in dataloader:\n",
    "    print(src.shape, tgt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (German):  Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
      "Target (English):  Two young, White males are outside near many bushes.\n",
      "Source Tensor:  tensor([   33,   170,   542,    56,   176,    36,   186,     6,    26,   220,\n",
      "        14393,  6193,     4])\n",
      "Target Tensor:  tensor([  36,   48,   10, 2267, 1582,   31,  112,  158,  634, 2613,    4])\n",
      "['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
      "[2267]\n"
     ]
    }
   ],
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
    "sample = next(iter(train_iter))\n",
    "print(\"Source (German): \", sample[0])\n",
    "print(\"Target (English): \", sample[1])\n",
    "\n",
    "# 데이터 하나를 텐서로 변환하기\n",
    "src_tensor = torch.tensor([vocab_de[token] for token in tokenize_de(sample[0])], dtype=torch.long)\n",
    "trg_tensor = torch.tensor([vocab_en[token] for token in tokenize_en(sample[1])], dtype=torch.long)\n",
    "\n",
    "print(\"Source Tensor: \", src_tensor)\n",
    "print(\"Target Tensor: \", trg_tensor)\n",
    "\n",
    "print(vocab_en.lookup_tokens(trg_tensor.numpy()))\n",
    "print(vocab_en.lookup_indices(['White']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
