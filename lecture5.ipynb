{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Tensor\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1ICXojPKmaPRqMB_xo4QoAhK1zEwMiN2F\">\n",
        "\n",
        "image는 가로, 세로로 픽셀들이 격자형태로 존재하는 데이터로 행렬로 취급할 수 있다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1XaUTJkCIzY8NcM3LrqhnimnTfc2y3ZSa\">\n",
        "\n",
        "- 흑백이미지는 : H × W\n",
        "- 컬러이미지는 : H × W × C\n",
        "- 컬러이미지 + batch-size : N × H × W × C"
      ],
      "metadata": {
        "id": "2dVtvVwV43KG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation\n",
        "image 데이터에 filter를 적용하는 연산으로 image와 kernel을 어떠한 방식으로 filtering할 것인가 하는 방법들 중 하나다.\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1lSZG1wp8zxoZwYHEmdAzHZO5BIyQWWjJ\">\n",
        "\n",
        "Correlation 연산이 딥러닝에 적용이되면\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1L_RYA5LZsmd1psRgMy44c_cGNLGh2Co5\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1Gf3qH7nbCeNc4L1iPQYuP1Ek96FNIkPX\">\n",
        "\n",
        "- filter가 weight matrix가 되면 bias가 추가된다.(Affine Transformation)\n",
        "- Activation function도 추가될 수 있다."
      ],
      "metadata": {
        "id": "5KAPvmtd53V6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Layer와 차이점\n",
        "input matrix와 filter matrix에 flatten을 적용하면 row vector의 형태로 만들 수 있다.  \n",
        "이 상태에서 correlation 연산을 진행해보면, 앞서 배운 Affine Transformation과 연산이 동일함을 볼 수 있다.  \n",
        "여기서 Dense layer는 모든 입력이 각각의 뉴런에 input으로 반영되었으나, correlation 연산은 그렇지 않다.(뒤에서 window와 convolution을 보면 이해된다.)\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1snwStb9dqnTg6gKjltudoGZXXFGajjZd\">"
      ],
      "metadata": {
        "id": "1sTA_QRa7rEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Windows\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1v672frL3rOD_hI3jclGR7lxC7E7kAJli\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1m2Oo3A-h3tleHSki2YBT2UvvhbgK8Gq2\">\n",
        "\n",
        "- 정해진 규격의 window가 input 벡터를 이동하며 값을 가져오게 된다.  \n",
        "- 2D 에서 i : height, j : width 를 가리킨다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1YsW8dXtvmbKLsWN0EqwMBr3AJdBg4DPd\">\n",
        "\n",
        "- Window의 크기는 f × f\n",
        "- window가 이미지의 n<sub>w</sub> - f 가 되어야 filter가 이미지의 마지막 width 픽셀까지 적용이 가능.\n",
        "- height도 마찬가지.\n",
        "- window에서 i + f, j + f로 적용하면, slicing이 end - 1까지 값을 가져오게 된다.\n",
        "- 따라서 X[i + (f - 1), j + (f - 1)]\n"
      ],
      "metadata": {
        "id": "ZKm4lP0HHclN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Computation\n",
        "\n",
        "### 1D convolutional\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1S4uiPdEiDEJs75BeRhE1YZIwAMhY1Kie\">\n",
        "\n",
        "### 2D convolutional\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1sWbSmhtTtxDypIyvV8s6ATrIeycqj2p9\">\n",
        "\n",
        "window와 correlation 연산이 모두 적용되는 형태로 convolution 연산이 이루어진다.\n",
        "- 정해진 규격의 window가 input을 순회.\n",
        "- window로 가져온 input의 부분 값과 Kernel(filter) 간의 correlation 연산 진행.\n",
        "- kernel의 size는 window의 size와 동일하다.\n",
        "- input을 모두 순회할 때까지 반복하고, 이들을 종합하여 output vector(matrix)를 만들어낸다.\n",
        "- convolution layer를 통과하게 되면, input image size가 축소된다.\n",
        "\n",
        "### 2D convolutional + Activation\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1pLARvvjQopgge05NFzi2t-eRQhPFvbwZ\">\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1Sqh6yrWp_XJ5MtH-GsDwmP5VdKChIplK\">"
      ],
      "metadata": {
        "id": "5q84J6nFPcmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RGB image\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=12Lz99A5LzkSTp8QP2PJe9iKQW3qM1O0m\">\n",
        "\n",
        "RGB image는 image matrix 3개가 하나의 데이터를 이루고 있다.\n",
        "- X[:, :, 0] - R\n",
        "- X[:, :, 1] - G\n",
        "- X[:, :, 2] - B\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1N9am48NhuRkB93Ld5qlPptgffuEpjH2W\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1IBpSFqeZHHQy6gtF_cMhEyvGuRUuWQbt\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1NMTeDBOWz-4pnhzfaz5lLIyH06Zt9pNy\">\n",
        "\n",
        "따라서 Window도 f × f 크기에 n<sub>c</sub>의 channel size를 가지게 된다.  \n",
        "- 가로, 세로의 크기가 5인 경우\n",
        "- Window : 5 × 5 × 3\n",
        "- RGB 채널을 한 번에 훑어 보는 window.\n",
        "- window의 크기와 동일하게 kernel size도 설정된다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M9ApuMigfQBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution layer Single filter\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=12eWibWc5c7ywPmA08IumkhXmnjTiVBLy\">\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1iHNvbfSRiNGKrlhMFHlGQbi3cx4vvHzg\">\n",
        "\n",
        "1개의 filter를 가진 Convolution layer.\n",
        "f×f×3크기의 window가 input X를 이동하며 correlation + Activation function을 진행한다.  \n",
        "따라서 스칼라인 결과값들로 구성된 output shape = H × W가 만들어지게 된다.\n",
        "\n",
        "(1개의 뉴런을 가진 dense layer와 동일한 개념이라고 보면 된다.)\n"
      ],
      "metadata": {
        "id": "f7b8HgUqhyFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution layer multiple kernel\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1iHNvbfSRiNGKrlhMFHlGQbi3cx4vvHzg\">\n",
        "\n",
        "1개의 convolution layer가 여러 개의 filter를 가지게 되는 경우,\n",
        "- filter의 shape은 모두 동일.\n",
        "- 단, 각각의 filter 내부 weight 값은 모두 다르다.\n",
        "- 각각의 filter를 거쳐서 얻은 output matrix를 모두 더함.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1C0sqxnwFYnYRgLp88rgT4szZ6uVSXz75\">\n",
        "\n",
        "- X가 l<sub>i</sub>개의 feature를 가지고 있다.\n",
        "- 첫번째 conv-layer는 f×f×3 에 l<sub>i</sub>개의 weight를 가지고 있으며 l<sub>1</sub>개의 filter를 가지고 있다.\n",
        "- 이를 통과하고 얻은 matrix의 형태는 H × W × l<sub>1</sub>\n",
        "- 위와 동일하게 다음 conv-layer를 통과."
      ],
      "metadata": {
        "id": "eK4uUbsQl-2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=18eefv6vyWxaum3BcdJF2aWhsJ9iIrmd3\">\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1uY4RVzAg7iJ_za9DBUNjLZgwm0fBBmKj\">"
      ],
      "metadata": {
        "id": "Q9jw3Y1An7rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Gray Scale image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "N, n_H, n_W, n_C = 1, 28, 28, 1\n",
        "n_filter = 1 ## num filter\n",
        "k_size = 3 ## kernel size\n",
        "\n",
        "images = tf.random.uniform(minval=0, maxval=1, shape=((N, n_H, n_W, n_C)))\n",
        "\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "y = conv(images)\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "print(images.shape)\n",
        "print(W.shape) ## H, W, C, N_filter(뉴런의 수)\n",
        "print(B.shape)\n",
        "print(y.shape) ## 28 - 3 + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfT_OqH4pCwL",
        "outputId": "b0f77c50-c056-4fa0-a24d-4697c4aa743c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 1)\n",
            "(3, 3, 1, 1)\n",
            "(1,)\n",
            "(1, 26, 26, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## RGB Scale image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "N, n_H, n_W, n_C = 1, 28, 28, 3\n",
        "n_filter = 1 ## num filter\n",
        "k_size = 3 ## kernel size\n",
        "\n",
        "images = tf.random.uniform(minval=0, maxval=1, shape=((N, n_H, n_W, n_C)))\n",
        "\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "y = conv(images)\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "print(images.shape)\n",
        "print(W.shape) ## H, W, C, N_filter(뉴런의 수)\n",
        "print(B.shape)\n",
        "print(y.shape) ## 28 - 3 + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsT8ILsfqE_u",
        "outputId": "3cab342e-2557-41ce-e98c-e90732085a0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 3)\n",
            "(3, 3, 3, 1)\n",
            "(1,)\n",
            "(1, 26, 26, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## numpy manual\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "N, n_H, n_W, n_C = 1, 5, 5, 1\n",
        "n_filter = 1 ## num filter\n",
        "k_size = 3 ## kernel size\n",
        "\n",
        "images = tf.random.uniform(minval=0, maxval=1, shape=((N, n_H, n_W, n_C)))\n",
        "\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "y = conv(images)\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "### manual\n",
        "images = images.numpy().squeeze()\n",
        "W = W.squeeze()\n",
        "\n",
        "y_man = np.zeros(shape=(n_H - k_size + 1, n_W - k_size + 1))\n",
        "for i in range(n_H - k_size + 1):\n",
        "    for j in range(n_W - k_size + 1):\n",
        "        # print(i, j)\n",
        "        window = images[i : i+k_size, j : j+k_size]\n",
        "        y_man[i, j] = np.sum(window * W) + B\n",
        "\n",
        "print(images.shape)\n",
        "print(W.shape)\n",
        "print(B.shape)\n",
        "\n",
        "print(f\"y tensorflow : {y.shape} \\n {y.numpy().squeeze()}\")\n",
        "print(f\"y man : {y_man.shape} \\n {y_man}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNieDey8qzXf",
        "outputId": "cbc1848c-8703-480f-b792-6bbc4d163007"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5)\n",
            "(3, 3)\n",
            "(1,)\n",
            "y tensorflow : (1, 3, 3, 1) \n",
            " [[-3.44581902e-04 -2.38220841e-02 -3.71550918e-01]\n",
            " [-3.21483195e-01 -4.65770662e-01 -3.98087680e-01]\n",
            " [-6.36238605e-02 -1.12412035e-01 -1.85237736e-01]]\n",
            "y man : (3, 3) \n",
            " [[-3.44574451e-04 -2.38220841e-02 -3.71550918e-01]\n",
            " [-3.21483165e-01 -4.65770602e-01 -3.98087740e-01]\n",
            " [-6.36238754e-02 -1.12412021e-01 -1.85237736e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pauTxlny4zF",
        "outputId": "885fd392-6f02-43e3-bffa-346d179f5ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5, 3)\n",
            "(3, 3, 3)\n",
            "(1,)\n",
            "y tensorflow : (1, 3, 3, 1) \n",
            " [[ 0.82929844 -0.01844898  0.672023  ]\n",
            " [ 0.512003    0.00407238  0.47438905]\n",
            " [-0.10338495  0.39780995  0.6445194 ]]\n",
            "y man : (3, 3) \n",
            " [[ 0.82929832 -0.01844907  0.67202294]\n",
            " [ 0.51200294  0.0040725   0.47438905]\n",
            " [-0.10338486  0.39780998  0.64451939]]\n"
          ]
        }
      ],
      "source": [
        "## numpy manual color image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "N, n_H, n_W, n_C = 1, 5, 5, 3\n",
        "n_filter = 1 ## num filter\n",
        "k_size = 3 ## kernel size\n",
        "\n",
        "images = tf.random.uniform(minval=0, maxval=1, shape=((N, n_H, n_W, n_C)))\n",
        "\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "y = conv(images)\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "### manual\n",
        "images = images.numpy().squeeze()\n",
        "W = W.squeeze()\n",
        "\n",
        "y_man = np.zeros(shape=(n_H - k_size + 1, n_W - k_size + 1))\n",
        "for i in range(n_H - k_size + 1):\n",
        "    for j in range(n_W - k_size + 1):\n",
        "        # print(i, j)\n",
        "        window = images[i : i+k_size, j : j+k_size, :]\n",
        "        y_man[i, j] = np.sum(window * W) + B\n",
        "\n",
        "print(images.shape)\n",
        "print(W.shape)\n",
        "print(B.shape)\n",
        "\n",
        "print(f\"y tensorflow : {y.shape} \\n {y.numpy().squeeze()}\")\n",
        "print(f\"y man : {y_man.shape} \\n {y_man}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## convolution multiple kernels\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "batch_size, height, width, channel = 10, 28, 28, 3\n",
        "n_filter = 5\n",
        "k_size = 3\n",
        "\n",
        "image = tf.random.uniform(minval=0, maxval = 1, shape=(batch_size, height, width, channel))\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "Y = conv(image)\n",
        "\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "print(image.shape)\n",
        "print(W.shape, B.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfxxykWQtaYV",
        "outputId": "70bdf84b-1554-476d-e0b3-0fd32b61ce78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28, 28, 3)\n",
            "(3, 3, 3, 5) (5,)\n",
            "(10, 26, 26, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=16hs-fKc4mKtax2zAqPEf8_q9oIM8fZHK\">"
      ],
      "metadata": {
        "id": "BpDPNAUnuuro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## conv layer output의 shape를 정리(N, H, W)하는 방법.\n",
        "import numpy as np\n",
        "\n",
        "images = np.random.randint(low=0, high=10, size=(2, 3, 4))\n",
        "for c in range(4):\n",
        "    print(images[:, :, c])\n",
        "\n",
        "images = np.transpose(images, (2, 0, 1))\n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7Gl4D80wP6",
        "outputId": "ee731f39-4536-4480-d6f5-3a0257cef3ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 2 3]\n",
            " [1 9 3]]\n",
            "[[7 7 8]\n",
            " [4 1 7]]\n",
            "[[3 1 1]\n",
            " [9 5 6]]\n",
            "[[1 4 6]\n",
            " [7 7 3]]\n",
            "(4, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## multiple kernel conv layer + manual\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "batch_size, height, width, channel = 1, 5, 5, 3\n",
        "n_filter = 5\n",
        "k_size = 3\n",
        "\n",
        "image = tf.random.uniform(minval=0, maxval = 1, shape=(batch_size, height, width, channel))\n",
        "\n",
        "## Tensorflow\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
        "Y = conv(image)\n",
        "Y = np.transpose(Y.numpy().squeeze(), (2, 0, 1))\n",
        "print(f\"Y tensorflow : {Y.shape} \\n {Y} \\n\")\n",
        "\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "## manual\n",
        "image = image.numpy().squeeze()\n",
        "print(image.shape)\n",
        "print(W.shape, B.shape) ## height, width ,channel, kernel\n",
        "\n",
        "Y_man = np.zeros(shape=(height - k_size + 1, width - k_size + 1, n_filter))\n",
        "for c in range(n_filter):\n",
        "    c_W = W[:, :, :, c] ## 3 by 3\n",
        "    c_b = B[c] ## 1\n",
        "\n",
        "    for h in range(height - n_filter + 1):\n",
        "        for w in range(width - n_filter + 1):\n",
        "            window = image[h:h+k_size, w:w+k_size, :]\n",
        "            conv = np.sum(window * c_W) + c_b\n",
        "\n",
        "            Y_man[h, w, c] = conv\n",
        "\n",
        "Y_man = np.transpose(Y_man, (2, 0, 1))\n",
        "print(f\"Y manual : {Y_man.shape}\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbCKqEaRvlrj",
        "outputId": "8cd285b8-b981-4fdb-9767-a9cce6965d8a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensorflow : (5, 3, 3) \n",
            " [[[-0.42933172 -0.5158518  -0.6199455 ]\n",
            "  [-0.12647565 -0.29189658 -0.28027344]\n",
            "  [-0.4321921  -0.71040654 -0.33408332]]\n",
            "\n",
            " [[-0.16057464  0.23892467 -0.09257627]\n",
            "  [ 0.0428706  -0.19386734 -0.3895949 ]\n",
            "  [-0.27564543 -0.3258912   0.27089885]]\n",
            "\n",
            " [[ 0.39249593  0.00245518 -0.00968595]\n",
            "  [ 0.12194953  0.56839156  0.27787998]\n",
            "  [ 0.68368     0.68982077  0.37812725]]\n",
            "\n",
            " [[ 0.7401816   0.7850511   0.36055082]\n",
            "  [ 0.83511335  0.3930271   0.35861918]\n",
            "  [ 0.6003498   0.20013998  0.1708646 ]]\n",
            "\n",
            " [[ 0.277403    0.51585066  0.7293358 ]\n",
            "  [ 0.7140047   0.41943935 -0.10798562]\n",
            "  [ 0.384962    0.1025049   0.3497496 ]]] \n",
            "\n",
            "(5, 5, 3)\n",
            "(3, 3, 3, 5) (5,)\n",
            "Y manual : (5, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## multiple kernel conv layer with activation func.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "batch_size, height, width, channel = 1, 5, 5, 3\n",
        "n_filter = 5\n",
        "k_size = 3\n",
        "\n",
        "image = tf.random.uniform(minval=0, maxval = 1, shape=(batch_size, height, width, channel))\n",
        "\n",
        "## Tensorflow\n",
        "conv = Conv2D(filters=n_filter, kernel_size=k_size, activation=\"sigmoid\")\n",
        "Y = conv(image)\n",
        "Y = np.transpose(Y.numpy().squeeze(), (2, 0, 1))\n",
        "print(f\"Y tensorflow : {Y.shape} \\n {Y} \\n\")\n",
        "\n",
        "W, B = conv.get_weights()\n",
        "\n",
        "## manual\n",
        "image = image.numpy().squeeze()\n",
        "print(image.shape)\n",
        "print(W.shape, B.shape) ## height, width ,channel, kernel\n",
        "\n",
        "Y_man = np.zeros(shape=(height - k_size + 1, width - k_size + 1, n_filter))\n",
        "for c in range(n_filter):\n",
        "    c_W = W[:, :, :, c] ## 3 by 3\n",
        "    c_b = B[c] ## 1\n",
        "\n",
        "    for h in range(height - n_filter + 1):\n",
        "        for w in range(width - n_filter + 1):\n",
        "            window = image[h:h+k_size, w:w+k_size, :]\n",
        "            conv = np.sum(window * c_W) + c_b\n",
        "\n",
        "            Y_man[h, w, c] = conv\n",
        "\n",
        "Y_man = np.transpose(Y_man, (2, 0, 1))\n",
        "print(f\"Y manual : {Y_man.shape}\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acQIjleR41vu",
        "outputId": "593642a4-7fbe-4cac-9814-2e7ef995b384"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensorflow : (5, 3, 3) \n",
            " [[[0.65439355 0.63572997 0.63958544]\n",
            "  [0.6601203  0.6343901  0.5939627 ]\n",
            "  [0.66795987 0.6899615  0.64574033]]\n",
            "\n",
            " [[0.30873513 0.29040682 0.23424667]\n",
            "  [0.32518047 0.3125997  0.39053205]\n",
            "  [0.28720295 0.27480793 0.27775887]]\n",
            "\n",
            " [[0.44636437 0.55486476 0.41662878]\n",
            "  [0.45851663 0.3183123  0.37474   ]\n",
            "  [0.45333079 0.5621858  0.37323558]]\n",
            "\n",
            " [[0.6593952  0.7342711  0.71645665]\n",
            "  [0.7017179  0.65005666 0.76184636]\n",
            "  [0.7330101  0.6818343  0.7809943 ]]\n",
            "\n",
            " [[0.43423197 0.5892751  0.43577167]\n",
            "  [0.52228576 0.48771918 0.34356016]\n",
            "  [0.49372223 0.41652912 0.50684434]]] \n",
            "\n",
            "(5, 5, 3)\n",
            "(3, 3, 3, 5) (5,)\n",
            "Y manual : (5, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "n_neurons = [10, 20, 30] ## num kernels\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=n_neurons[0], kernel_size=kernel_size, activation=\"relu\"))\n",
        "model.add(Conv2D(filters=n_neurons[1], kernel_size=kernel_size, activation=\"relu\"))\n",
        "model.add(Conv2D(filters=n_neurons[2], kernel_size=kernel_size, activation=\"relu\"))\n",
        "\n",
        "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
        "predictions = model(x)\n",
        "\n",
        "print(f\"Input : {x.shape}\")\n",
        "print(f\"Output : {predictions.shape}\")\n",
        "\n",
        "for layer in model.layers:\n",
        "    W, B = layer.get_weights()\n",
        "    print(W.shape, B.shape)\n",
        "\n",
        "print(\"==================\")\n",
        "trainable_variables = model.trainable_variables\n",
        "for train_var in trainable_variables:\n",
        "    print(train_var.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk3pQm366hNN",
        "outputId": "8eda5673-c3b5-4153-80b8-d431925f1aaf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : (32, 28, 28, 3)\n",
            "Output : (32, 22, 22, 30)\n",
            "(3, 3, 3, 10) (10,)\n",
            "(3, 3, 10, 20) (20,)\n",
            "(3, 3, 20, 30) (30,)\n",
            "==================\n",
            "(3, 3, 3, 10)\n",
            "(10,)\n",
            "(3, 3, 10, 20)\n",
            "(20,)\n",
            "(3, 3, 20, 30)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=1-WsqF4J4CIDSgaZooBjnx-s3hP3Yu8Db\">"
      ],
      "metadata": {
        "id": "tMayuWIw8lKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "n_neurons = [10, 20, 30] ## num kernels\n",
        "\n",
        "class TestModel(Model):\n",
        "    def __init__(self):\n",
        "        super(TestModel, self).__init__()\n",
        "        global n_neurons\n",
        "\n",
        "        self.conv_layers = []\n",
        "        for n_neuron in n_neurons:\n",
        "            self.conv_layers.append(Conv2D(filters=n_neuron, kernel_size=kernel_size, activation=\"relu\"))\n",
        "\n",
        "    def call(self, x):\n",
        "        print(\"input : \", x.shape)\n",
        "\n",
        "        print(\"===== conv layers =====\")\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "            W, B = conv_layer.get_weights()\n",
        "            print(W.shape, B.shape)\n",
        "            print(f\"{x.shape} \\n\")\n",
        "\n",
        "        return x\n",
        "\n",
        "model = TestModel()\n",
        "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
        "predictions = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx16eoer7AZ2",
        "outputId": "f0a23614-0da1-47c8-ed55-a2da12e14506"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  (32, 28, 28, 3)\n",
            "===== conv layers =====\n",
            "(3, 3, 3, 10) (10,)\n",
            "(32, 26, 26, 10) \n",
            "\n",
            "(3, 3, 10, 20) (20,)\n",
            "(32, 24, 24, 20) \n",
            "\n",
            "(3, 3, 20, 30) (30,)\n",
            "(32, 22, 22, 30) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "n_neurons = [10, 20, 30] ## num kernels\n",
        "\n",
        "class TestModel(Model):\n",
        "    def __init__(self):\n",
        "        super(TestModel, self).__init__()\n",
        "        global n_neurons\n",
        "\n",
        "        self.conv1 = Conv2D(filters=n_neurons[0], kernel_size=3, activation=\"relu\")\n",
        "        self.conv2 = Conv2D(filters=n_neurons[1], kernel_size=3, activation=\"relu\")\n",
        "        self.conv3 = Conv2D(filters=n_neurons[2], kernel_size=3, activation=\"relu\")\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = TestModel()\n",
        "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
        "predictions = model(x)"
      ],
      "metadata": {
        "id": "3xuUXmiz9UqU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDnxWXtO-yi_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}