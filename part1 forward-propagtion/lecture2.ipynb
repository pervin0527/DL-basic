{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHTZnLIlOcaKhNpdmemPoT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Layers\n","layer는 뉴런들의 집합이다.\n","\n","1개의 뉴런은 lecture1에서 배운 Affine transformation과 Activation function의 조합으로 구성되어 있다.\n","<img src=\"https://drive.google.com/uc?export=download&id=1qHhyjBv6ntOdTPfeRjKSSzw1Q4Ap2cId\">\n","\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1fmcvYvBK5a1bOk-x5u6JSSaFeqVSjqw2\">\n","\n","layer는 n개의 뉴런들이 모여서 이루는 뉴런 벡터 또는 뉴런들의 집합으로 생각할 수 있다.\n","\n","이때 중요한 점은 각각의 뉴런들은 가지고 있는 parameter(weight, bias)들의 값이 모두 다르다.  \n","따라서 뉴런들이 동일한 입력을 받아도 각각의 뉴런들이 출력하는 output은 모두 제각각이다.\n","\n","Activation Function은 parameter를 가지지 않기 때문에 Parametric Function이 아니다."],"metadata":{"id":"2UktbcEVX4F2"}},{"cell_type":"markdown","source":["## Dense Layer\n","dense layer는 layer의 각 뉴런이 모든 input들을 받는 layer이다. \n","<img src=\"https://drive.google.com/uc?export=download&id=1loCPF5u3GPVE5tPpgBgT2oRXJRDfCpGf\">\n","<img src=\"https://drive.google.com/uc?export=download&id=16Qxnw6uUxQXhyL810inGTl0BvkhXofOA\">\n"],"metadata":{"id":"W4oUIMNZZvj7"}},{"cell_type":"markdown","source":["### 세부구조\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1PW78TIKuy7nLfUh5wXfuzhsw3f-G6dKh\">\n","\n","{W<sub>k</sub><sub>j</sub>}<sup>[i]</sup>\n","- i : 몇번째 layer인가.\n","- j : layer 내에서 몇번째 뉴런인가.\n","- k : 뉴런 내에서 몇번째 weight인가.\n","\n","각각의 뉴런들이 가지고 있는 weight, bias들을 각각 관리하기 귀찮으므로 행렬의 형태로 변환한다.<img src=\"https://drive.google.com/uc?export=download&id=1RLI6oVBv8W5BauEjecdSudUjgiz6N3Rp\">\n","\n"],"metadata":{"id":"uKDVDwpTgRHJ"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","N, n_feature = 1, 10 ## batch-size : 1, row vectors : 10 // (1, 10) input matrix\n","X = tf.random.normal(shape=(N, n_feature))\n","\n","n_neuron = 3\n","dense = tf.keras.layers.Dense(units=n_neuron, activation=\"sigmoid\") ## 3 neurons // (10 x 3) weight matrix\n","## Column wise == neuron\n","## 1열 : 1번 뉴런, 2열 : 2번 뉴런, 3열 : 3번 뉴런\n","\n","Y = dense(X)\n","W, B = dense.get_weights()\n","\n","print(f\"X : {X.shape} \\n {X.numpy()} \\n\")\n","print(f\"W : {W.shape} \\n {W} \\n\")\n","print(f\"B : {B.shape} \\n {B} \\n\")\n","print(f\"Y : {Y.shape} \\n {Y.numpy()} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuvNR9hxMwkm","executionInfo":{"status":"ok","timestamp":1676872889331,"user_tz":-540,"elapsed":4265,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"ce2a1398-2cf9-4282-e641-4620bfc10897"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X : (1, 10) \n"," [[-0.24915768 -0.01650841  0.05331842 -1.1055087  -1.0772789  -2.560363\n","  -0.4165717   0.7165221   0.8822942  -0.8384255 ]] \n","\n","W : (10, 3) \n"," [[ 0.5867919  -0.5639609  -0.6416578 ]\n"," [ 0.5128391   0.20828098 -0.18587887]\n"," [ 0.39804256  0.21382582  0.00863415]\n"," [ 0.5175458   0.21059829 -0.24433091]\n"," [-0.6426642   0.6496494   0.632643  ]\n"," [ 0.59067523  0.53283644 -0.11620384]\n"," [ 0.21018624 -0.11227214  0.16085815]\n"," [-0.61708987  0.5211654   0.57554007]\n"," [ 0.342363    0.28888625 -0.17383581]\n"," [-0.5415174   0.21086365 -0.58172095]] \n","\n","B : (3,) \n"," [0. 0. 0.] \n","\n","Y : (1, 3) \n"," [[0.21429257 0.16108681 0.6746379 ]] \n","\n"]}]},{"cell_type":"code","source":["## self\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.initializers import Constant\n","\n","w, b = tf.constant(2.), tf.constant(1.)\n","w_init, b_init = Constant(w), Constant(b)\n","\n","X = tf.random.uniform(shape=(3, 3), minval=0, maxval=9, dtype=tf.int32)\n","dense = tf.keras.layers.Dense(units=5, \n","                              activation=\"linear\", \n","                              kernel_initializer=w_init, \n","                              bias_initializer=b_init)\n","Y = dense(X)\n","\n","W, B = dense.get_weights() ## Bias도 뉴런의 수만큼 생성된다.\n","\n","print(f\"Input : {X.shape} \\n {X.numpy()} \\n\")\n","print(f\"Weight : {W.shape} \\n {W} \\n\")\n","print(f\"Bias : {B.shape} \\n {B} \\n\")\n","print(f\"Output : {Y.shape} \\n {Y.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8BxET3GAtJ8","executionInfo":{"status":"ok","timestamp":1677135210672,"user_tz":-540,"elapsed":6,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"71b5c83f-f288-4f32-fb5e-c9e9005c0919"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Input : (3, 3) \n"," [[5 7 4]\n"," [6 2 4]\n"," [4 3 8]] \n","\n","Weight : (3, 5) \n"," [[2. 2. 2. 2. 2.]\n"," [2. 2. 2. 2. 2.]\n"," [2. 2. 2. 2. 2.]] \n","\n","Bias : (5,) \n"," [1. 1. 1. 1. 1.] \n","\n","Output : (3, 5) \n"," [[33. 33. 33. 33. 33.]\n"," [25. 25. 25. 25. 25.]\n"," [31. 31. 31. 31. 31.]]\n"]}]},{"cell_type":"markdown","source":["## Forward Propagation\n","<img src=\"https://drive.google.com/uc?export=download&id=1kiCuIlaI8OOJaJzSESGhbqtMCxKMzMzA\">\n","\n","- input x<sub>l<sub>i</sub></sub>만큼 weight vector의 차원이 동일하게 맞춰진다.\n","- l<sub>i</sub>개의 weight를 가진 뉴런들이 <sub>1</sub>개 존재하므로, weight matrix는 l<sub>i</sub> × l<sub>1</sub>\n","- x(row vector)와 weight matrix 간의 dot product(inner product)를 통해 l<sub>i</sub> × 1 의 row vector를 얻게된다.\n","- 마지막으로 bias vector(row form)을 더해주면 layer_1의 연산이 끝난 것이다."],"metadata":{"id":"fuQV2x4plxyN"}},{"cell_type":"code","source":["N, n_feature = 8, 10 ## batch-size : 8, row vectors : 10 // (8, 10) input matrix\n","X = tf.random.normal(shape=(N, n_feature))\n","\n","n_neuron = 3\n","dense = tf.keras.layers.Dense(units=n_neuron, activation=\"sigmoid\") ## 3 neurons // (10 x 3) weight matrix\n","## Column wise == neuron\n","\n","Y = dense(X)\n","\n","W, B = dense.get_weights()\n","\n","print(f\"X : {X.shape} \\n {X.numpy()} \\n\")\n","print(f\"W : {W.shape} \\n {W} \\n\")\n","print(f\"B : {B.shape} \\n {B} \\n\")\n","print(f\"Y : {Y.shape} \\n {Y.numpy()} \\n\") ## Row wise == input matrix의 row(data sample)과 weight matrix의 column(neuron) 간 dot product"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0waHMrX_NmGv","executionInfo":{"status":"ok","timestamp":1676618042453,"user_tz":-540,"elapsed":274,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"a663e08a-405a-48fe-d94a-02e827bc1e8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X : (8, 10) \n"," [[ 0.86356735  0.34199923 -0.04937594  0.9168514   2.0846777  -0.21359067\n","  -0.5370583   0.09552217  0.7897584  -1.2188591 ]\n"," [-0.3305922   0.55810815  1.0076561   0.06520826 -0.6828096   1.5428512\n","   0.4369008   2.1800418   1.2655302  -0.10741881]\n"," [-0.280456   -0.5860013  -0.11978532 -0.19179282 -2.4775827  -1.2100868\n","   1.7028368  -0.08767257 -0.18099645 -0.06131132]\n"," [-1.7963477  -0.9407741  -0.07166364 -0.786007    0.8271763  -0.29297012\n","   0.54351187 -0.63952667 -0.13407816  0.6640327 ]\n"," [ 1.1123961  -1.77827    -1.2147692   0.12370616 -0.41512802  0.48415267\n","  -0.35735843 -0.29713038 -2.1594112  -0.5408446 ]\n"," [ 1.1393626   0.3490962  -0.03056625 -0.5924678  -0.3559421  -0.14887623\n","   0.10820436 -0.35138658  1.0900651  -0.1889676 ]\n"," [ 0.46844515  1.272012    0.10104561 -1.3986534   0.29258227  0.53944093\n","   0.21019259 -0.59052056 -0.50973344 -0.018357  ]\n"," [ 0.38321337 -0.47588986 -0.00548279 -0.44662064  0.2953757  -0.43118733\n","   0.12399973  0.10197753 -1.1070335  -0.12350712]] \n","\n","W : (10, 3) \n"," [[-0.42069063 -0.3651337   0.13952738]\n"," [-0.2722668  -0.6490796   0.40278602]\n"," [-0.06344372 -0.03261757 -0.21400446]\n"," [-0.56328434 -0.26690647 -0.49920565]\n"," [ 0.16822618  0.12376398 -0.4627077 ]\n"," [ 0.4597392   0.29579866  0.5728749 ]\n"," [-0.07715786 -0.28781044 -0.14014924]\n"," [ 0.2734285   0.09218061 -0.05661523]\n"," [-0.6381036  -0.677003   -0.44274592]\n"," [ 0.57757056 -0.4260733  -0.040196  ]] \n","\n","B : (3,) \n"," [0. 0. 0.] \n","\n","Y : (8, 3) \n"," [[0.134984   0.39232576 0.18143538]\n"," [0.5433159  0.34169754 0.59619427]\n"," [0.34181243 0.3831423  0.5370059 ]\n"," [0.84759784 0.7477883  0.314379  ]\n"," [0.76642025 0.9317784  0.75975126]\n"," [0.21820341 0.2154186  0.5525553 ]\n"," [0.6620025  0.45192173 0.84001607]\n"," [0.6737329  0.72574955 0.5434337 ]] \n","\n"]}]},{"cell_type":"code","source":["X = tf.random.normal(shape=(16, 5)) ## 5차원 row vector가 16개가 한묶음\n","dense = tf.keras.layers.Dense(units=4, activation=\"sigmoid\") ## 뉴런이 4개인 layer. 5 by 4 matrix.\n","Y = dense(X) ## 16 by 4\n","\n","W, b = dense.get_weights()\n","print(f\"X : {X.shape} \\n {X.numpy()}\")\n","print(f\"W : {W.shape} \\n {W}\")\n","print(f\"b : {b.shape} \\n {b}\")\n","print(f\"Y : {Y.shape} \\n {Y}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRYcyjUfa6f9","executionInfo":{"status":"ok","timestamp":1676873281363,"user_tz":-540,"elapsed":268,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"0d38cf06-4305-4af9-f351-7a7cadb05fba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X : (16, 5) \n"," [[-1.2542684  -0.29523227  0.3044863   0.40145037 -0.55971   ]\n"," [-0.66338795  1.8652354   1.0352159   0.16756272  1.3720359 ]\n"," [ 0.35065296 -1.3674057  -0.7195325   0.43773213 -1.7857894 ]\n"," [ 1.4083174  -1.6047513  -1.5126861  -0.16746797 -0.33231178]\n"," [-2.0493379  -0.54980755 -0.8427084   1.3903923  -0.7814952 ]\n"," [ 0.29972228 -0.13862365  1.4724296  -0.87355083  0.43665645]\n"," [ 0.8137328  -1.5775731   0.80102754 -0.06934482 -0.40610322]\n"," [ 1.7241671   0.1391657  -0.62770087  0.40551665  0.4652951 ]\n"," [ 0.37758306 -0.3923751  -1.0472332  -0.8208615  -1.1105458 ]\n"," [-1.5060605  -0.5038025   0.14006555  0.41675258  0.5384123 ]\n"," [ 1.148592   -0.9473977   0.46976498 -0.68402284 -0.27519414]\n"," [ 0.91028273 -0.09760773  0.3327122   0.4382891   0.23806292]\n"," [-0.23569639  1.1383486   1.1384698  -1.0441151   1.9330343 ]\n"," [-1.9129155   2.267934   -1.6194302   1.476787   -1.0326943 ]\n"," [ 0.11850864  0.08111261  0.04322146  0.27080342 -0.93666047]\n"," [-0.32779893  1.4619396   1.5778675   0.11868551 -1.0635842 ]]\n","W : (5, 4) \n"," [[-0.37726924  0.01651853  0.70688784  0.17513865]\n"," [ 0.3339398   0.653877    0.7326485   0.1266576 ]\n"," [-0.6001376   0.15458542 -0.7038372   0.6126549 ]\n"," [-0.3784096  -0.42490506  0.12608546  0.37230694]\n"," [-0.6992625   0.08495504 -0.6894421   0.56048775]]\n","b : (4,) \n"," [0. 0. 0. 0.]\n","Y : (16, 4) \n"," [[0.6061948  0.40496406 0.293026   0.44157633]\n"," [0.31627575 0.80440694 0.31955567 0.8300082 ]\n"," [0.7162611  0.20796126 0.7386316  0.19932045]\n"," [0.5340371  0.22847196 0.74884903 0.24379887]\n"," [0.75317585 0.23490736 0.36720312 0.2962518 ]\n"," [0.26545507 0.6341812  0.2079652  0.70193684]\n"," [0.26809213 0.28919324 0.29460126 0.544885  ]\n"," [0.33045894 0.47244486 0.8165113  0.58584124]\n"," [0.80879337 0.46063834 0.7987783  0.17462166]\n"," [0.44564003 0.38603967 0.1357594  0.55358475]\n"," [0.35885158 0.43521032 0.472693   0.49001688]\n"," [0.287407   0.45925033 0.5569793  0.65644914]\n"," [0.2367153  0.821172   0.16822466 0.8168427 ]\n"," [0.9317707  0.61911285 0.91272587 0.2556084 ]\n"," [0.62455684 0.46680814 0.6884099  0.40934932]\n"," [0.5899463  0.74147373 0.6170517  0.632395  ]]\n"]}]},{"cell_type":"code","source":["## Manual\n","import numpy as np\n","\n","N, n_feature = 4, 10\n","X = tf.random.normal(shape=(N, n_feature))\n","\n","n_neuron = 3\n","dense = tf.keras.layers.Dense(units=n_neuron, activation=\"sigmoid\")\n","Y_tf = dense(X)\n","\n","W, B = dense.get_weights()\n","\n","## calculate with matrix multiplication.\n","Z = tf.linalg.matmul(X, W) + B\n","Y_man_mat_mul = 1 / (1 + tf.math.exp(-Z))\n","\n","## calculate with dot product.\n","Y_man_vec = np.zeros(shape=(N, n_neuron))\n","for x_idx in range(N):\n","  x = X[x_idx] ## row 단위로 접근.\n","\n","  for neuron_idx in range(n_neuron):\n","    w, b = W[:, neuron_idx], B[neuron_idx] ## W[:, neuron_idx] column 단위로 접근.\n","    z = tf.reduce_sum(x * w) + b\n","    a = 1 / (1 + np.exp(-z))\n","    Y_man_vec[x_idx, neuron_idx] = a\n","\n","\n","print(f\"Y tensorflow : {Y_tf.shape}, \\n {Y_tf.numpy()} \\n\")\n","print(f\"Y man mat_mul : {Y_man_mat_mul.shape}, \\n {Y_man_mat_mul} \\n\")\n","print(f\"Y man vec : {Y_man_vec.shape} \\n {Y_man_vec} \\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MxcdEfxOQmW","executionInfo":{"status":"ok","timestamp":1676619062944,"user_tz":-540,"elapsed":299,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"0c738ce7-99c4-4619-9be6-9ab470b5f4c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Y tensorflow : (4, 3), \n"," [[0.8620618  0.6017868  0.8499242 ]\n"," [0.46004727 0.8892391  0.8564313 ]\n"," [0.48217875 0.762668   0.66504467]\n"," [0.14955254 0.1649891  0.24311396]] \n","\n","Y man mat_mul : (4, 3), \n"," [[0.8620618  0.6017868  0.8499242 ]\n"," [0.46004725 0.889239   0.85643125]\n"," [0.48217872 0.76266795 0.6650446 ]\n"," [0.14955254 0.1649891  0.24311395]] \n","\n","Y man vec : (4, 3) \n"," [[0.86206178 0.60178682 0.84992421]\n"," [0.46004726 0.8892391  0.8564313 ]\n"," [0.48217873 0.76266795 0.66504461]\n"," [0.14955256 0.16498911 0.24311398]] \n","\n"]}]},{"cell_type":"markdown","source":["## Add second Dense Layer\n","<img src=\"https://drive.google.com/uc?export=download&id=1ecTOm-jmKQfLrZxjxjI8wTKwrv1Ti7fy\">\n","<img src=\"https://drive.google.com/uc?export=download&id=1ADkmcEuKtxsiQ4SLhRfsdXUj367bg9U7\">\n","<img src=\"https://drive.google.com/uc?export=download&id=1-V5H-0v1bDhbeWojCpUa89147JMlpEhH\">\n","\n","이제 dense layer를 하나 추가한다. 전반적인 연산 과정은 이전과 동일하지만  \n","주목해야할 점은 \n","- layer_1의 output이 layer_2의 input으로 사용된다.\n","- layer_1의 output shape : 1 × l<sub>1</sub>\n","- weight의 수는 input의 차원과 동일해야하므로, l<sub>1</sub> × l<sub>2</sub>"],"metadata":{"id":"ZA_3EuEs53QV"}},{"cell_type":"markdown","source":["## Generalize Dense Layer\n","일반화된 수식으로 앞에서 다룬 내용을 정리해보자.\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=1DLFeTMaQ0RfMydThYvto_eoQ5q_x52O0\">\n","<img src=\"https://drive.google.com/uc?export=download&id=1VV73NLtIyYKUMzybk8bzJm3Rk1Bvn-jH\">\n","\n","- i-1번째 layer의 출력값이 i번째의 입력으로 사용된다.\n","- 만약 i-1번째 layer의 출력값 형태가 1 × l<sub>i-1</sub>라면\n","- i번째 layer의 weight matrix는 i<sub>i-1</sub> × i<sub>i</sub>\n","- 즉 weight vector의 shape은 i<sub>i-1</sub> × 1"],"metadata":{"id":"nnpkMrny7pEx"}},{"cell_type":"markdown","source":["## Minibatch in Dense Layers\n","minibatch는 row vector들을 쌓은 행렬이라고 lecture 1에서 다루었다.  \n","또한 minibatch가 되었다고 해서, layer의 parameter의 수나 값이 변하지 않는다. \n","<img src=\"https://drive.google.com/uc?export=download&id=1v3roV_EASesuxSQY6uaKGVXgwP3OigR9\"> \n","\n","그렇다면 dense layer로 minibatch를 입력했을 때의 연산과정을 살펴보자.\n","<img src=\"https://drive.google.com/uc?export=download&id=1BlokXqSS2wGRik0bUv5v6GqWf4TqozXs\">\n","\n","전체적인 연산과정은 동일하다.\n","- 입력이 행렬로 바뀌었으므로, row vector x<sup>1</sup>이 weight matrix를 column wise로 dot product를 수행.\n","- 그 결과가 Matrix A의 첫번째 row가 된다.\n","- 다음으로 row vector x<sup>2</sup>가 weight matrix를 column wise로 dot product.\n","- 결과 row vector가 Matrix A의 두번째 row가 된다.\n","- N번째까지 동일하게 연산이 진행된다."],"metadata":{"id":"8c_aAfMb_0X-"}},{"cell_type":"markdown","source":["### 출력값 행렬 분석\n","\n","<img src=\"https://drive.google.com/uc?export=download&id=141jLWopFztKAOzOEiKwDYBlFwFig4bI9\">\n","\n","Matrix A의 \n","- row들은 minibatch인 X의 행렬을 row vector단위로 layer가 가진 각각의 뉴런들을 거쳐서 얻은 결과값들이다.(Batch된 data단위, batch-wise)\n","- column들은 minbatch X 행렬의 i번째 column이 layer의 i번째 뉴런을 거쳐서 얻은 결과값들이다.(i번째 뉴런 단위, neuron-wise)"],"metadata":{"id":"2nO7tm3VJ48n"}},{"cell_type":"code","source":["## Multiple Dense layers\n","\n","N, n_feature = 4, 10\n","X = tf.random.normal(shape=(N, n_feature))\n","\n","n_neurons = [3, 5]\n","dense1 = tf.keras.layers.Dense(units=n_neurons[0], activation=\"sigmoid\") ## layer를 거쳐도 minibatch size N은 바뀌지 않는다!!!\n","dense2 = tf.keras.layers.Dense(units=n_neurons[1], activation=\"sigmoid\") ## layer를 거쳐도 minibatch size N은 바뀌지 않는다!!!\n","\n","A1 = dense1(X)\n","Y = dense2(A1)\n","\n","W1, B1 = dense1.get_weights()\n","W2, B2 = dense2.get_weights()\n","\n","print(f\"X : {X.shape} \\n {X.numpy()} \\n\")\n","\n","print(f\"W1 : {W1.shape} \\n {W1} \\n\")\n","print(f\"B2 : {B1.shape} \\n {B1} \\n\")\n","print(f\"A1 : {A1.shape} \\n {A1.numpy()} \\n\")\n","\n","print(f\"W2 : {W2.shape} \\n {W2} \\n\")\n","print(f\"B2 : {B2.shape} \\n {B2} \\n\")\n","print(f\"Y : {Y.shape} \\n {Y.numpy()} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ti-0JsfjQEkj","executionInfo":{"status":"ok","timestamp":1676619928533,"user_tz":-540,"elapsed":280,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"b8e172a6-5b7a-4510-aea3-9d0d8ebe7e65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X : (4, 10) \n"," [[-1.1527294   1.028705   -0.30607077 -2.5039365  -1.0834688   1.7216122\n","   1.4004226  -0.3131567   0.11873918  2.0624187 ]\n"," [ 0.25842085  1.8076994   1.2125925  -0.25394768 -0.9753505  -0.33679712\n","  -0.82873064 -1.0289067  -0.04862465  0.75584316]\n"," [ 2.4999115   0.41161326  1.0856723  -0.617261   -0.32245123  0.13356194\n","   1.1235652   0.5338114   0.9207963   0.04049225]\n"," [ 0.4263557  -0.9590861   0.5813131   0.3872085   1.7720155  -1.3388429\n","   0.23468076 -0.3905542  -1.9063684  -0.2379089 ]] \n","\n","W1 : (10, 3) \n"," [[ 0.48086655 -0.06317729  0.07546592]\n"," [ 0.4748925   0.6446307  -0.11569577]\n"," [ 0.07855749  0.03108013  0.08240193]\n"," [ 0.3398018  -0.40620226 -0.27289188]\n"," [ 0.07079488  0.09826237 -0.62729937]\n"," [ 0.16344571  0.67326534 -0.52377284]\n"," [ 0.32270765  0.5499846   0.3095672 ]\n"," [-0.06496853 -0.58941895 -0.64709884]\n"," [ 0.515689    0.17054874  0.5042536 ]\n"," [-0.1958754  -0.04225695 -0.15172416]] \n","\n","B2 : (3,) \n"," [0. 0. 0.] \n","\n","A1 : (4, 3) \n"," [[0.3528678  0.97549534 0.64865315]\n"," [0.62101996 0.74605    0.7384405 ]\n"," [0.88764954 0.71274406 0.72944766]\n"," [0.26855502 0.18732461 0.28398457]] \n","\n","W2 : (3, 5) \n"," [[ 0.1020304   0.7117205   0.2030111  -0.52671695  0.6107586 ]\n"," [-0.3594994   0.4267606   0.13431627 -0.3883708   0.69217604]\n"," [-0.442925    0.7463997   0.56210846 -0.38952005 -0.86571544]] \n","\n","B2 : (5,) \n"," [0. 0. 0. 0. 0.] \n","\n","Y : (4, 5) \n"," [[0.35388824 0.7598032  0.638134   0.30632034 0.5815605 ]\n"," [0.37007025 0.7877723  0.6550618  0.28813004 0.5637541 ]\n"," [0.380187   0.81463134 0.66506857 0.26337823 0.59964585]\n"," [0.45866302 0.6184666  0.5595438  0.41950113 0.5119563 ]] \n","\n"]}]},{"cell_type":"code","source":["## dense layer with python list\n","N, n_feature = 4, 10\n","X = tf.random.normal(shape=(N, n_feature))\n","\n","n_neurons = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n","dense_layers = list()\n","for n_neuron in n_neurons:\n","  dense = tf.keras.layers.Dense(units=n_neuron, activation=\"relu\")\n","  dense_layers.append(dense)\n","\n","print(f\"Input X : {X.shape}\")\n","for dense_idx, dense in enumerate(dense_layers):\n","  # print(dense)\n","  X = dense(X)\n","  print(f\"After {dense_idx+1} dense layer : {X.shape}\")\n","\n","print(f\"Output X : {X.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MeWmIe_XUyqN","executionInfo":{"status":"ok","timestamp":1676620578255,"user_tz":-540,"elapsed":275,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"f5e34932-5089-4607-8bd3-37b9aed72e29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input X : (4, 10)\n","After 1 dense layer : (4, 10)\n","After 2 dense layer : (4, 20)\n","After 3 dense layer : (4, 30)\n","After 4 dense layer : (4, 40)\n","After 5 dense layer : (4, 50)\n","After 6 dense layer : (4, 60)\n","After 7 dense layer : (4, 70)\n","After 8 dense layer : (4, 80)\n","After 9 dense layer : (4, 90)\n","After 10 dense layer : (4, 100)\n","Output X : (4, 100)\n"]}]},{"cell_type":"code","source":["N, n_feature = 4, 10\n","X = tf.random.normal(shape=(N, n_feature))\n","X_copy = tf.identity(X)\n","\n","n_neurons = [3, 4, 5]\n","dense_layers = list()\n","for n_neuron in n_neurons:\n","  dense = tf.keras.layers.Dense(units=n_neuron, activation=\"sigmoid\")\n","  dense_layers.append(dense)\n","\n","print(f\"Input : {X.shape}\")\n","\n","W, B = list(), list()\n","for dense_idx, dense in enumerate(dense_layers):\n","  X = dense(X)\n","  w, b = dense.get_weights()\n","\n","  W.append(w), B.append(b)\n","\n","print(f\"Y tf : \\n {X.numpy()}\")\n","\n","\n","for layer_idx in range(len(n_neurons)):\n","  w, b = W[layer_idx], B[layer_idx]\n","  X_copy = tf.linalg.matmul(X_copy, w) + b\n","  X_copy = 1 / (1 + tf.math.exp(-X_copy))\n","\n","print(f\"Y man : \\n {X_copy.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5htq3ksW7We","executionInfo":{"status":"ok","timestamp":1676622508070,"user_tz":-540,"elapsed":274,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"cfc1964e-f9c4-4ead-f485-9400e34702aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input : (4, 10)\n","Y tf : \n"," [[0.47295672 0.60801417 0.54474163 0.3138575  0.47409844]\n"," [0.4496807  0.59281564 0.55678976 0.31927904 0.47951674]\n"," [0.45077643 0.59325194 0.5529749  0.31480235 0.47498667]\n"," [0.44855917 0.5918597  0.5541313  0.31528392 0.47552872]]\n","Y man : \n"," [[0.47295672 0.6080141  0.5447417  0.31385753 0.4740984 ]\n"," [0.4496807  0.59281564 0.55678976 0.31927904 0.4795167 ]\n"," [0.4507764  0.59325194 0.5529748  0.31480238 0.47498664]\n"," [0.44855917 0.59185964 0.5541313  0.31528395 0.47552872]]\n"]}]},{"cell_type":"code","source":["## input\n","X = tf.random.normal(shape=(4, 10))"],"metadata":{"id":"mPopVfbpgeuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Model Implemetation - Use Sequential\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Dense(units=10, activation=\"sigmoid\"))\n","model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\"))\n","\n","Y = model(X)\n","print(Y.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PmOrIPc7ZViw","executionInfo":{"status":"ok","timestamp":1676622877055,"user_tz":-540,"elapsed":346,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"742e5052-544e-4289-82d7-980489db8b94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.5006219  0.46653876 0.5551453  0.40625468 0.34165624 0.38242137\n","  0.5382013  0.68218315 0.6575505  0.59405124 0.55194455 0.3578304\n","  0.3743886  0.40750426 0.4631241  0.578291   0.5455659  0.33900678\n","  0.52721584 0.6127003 ]\n"," [0.5000555  0.4665051  0.5552435  0.40685174 0.34211385 0.3825857\n","  0.5383901  0.68171555 0.65690327 0.59400547 0.55074584 0.3586409\n","  0.37442502 0.40746313 0.46323022 0.5779435  0.5458325  0.3391968\n","  0.52779263 0.6122682 ]\n"," [0.5000209  0.46660045 0.5552221  0.4067525  0.34196702 0.3825257\n","  0.5382395  0.6817353  0.6570728  0.5939487  0.55093724 0.35852605\n","  0.37445638 0.40753046 0.46315378 0.5780489  0.5457346  0.3389862\n","  0.5277787  0.6124163 ]\n"," [0.49996957 0.46659717 0.55523044 0.40680787 0.34201202 0.3825423\n","  0.5382554  0.6816917  0.6570127  0.5939449  0.5508252  0.35860315\n","  0.37445897 0.4075287  0.46316567 0.5780175  0.5457598  0.33900386\n","  0.52783346 0.61237395]]\n"]}]},{"cell_type":"code","source":["## Model Implemetation - Use Subclassing\n","\n","class TestModel(tf.keras.models.Model):\n","    def __init__(self):\n","        super(TestModel, self).__init__()\n","\n","        self.dense1 = tf.keras.layers.Dense(units=10, activation=\"sigmoid\")\n","        self.dense2 = tf.keras.layers.Dense(units=20, activation=\"sigmoid\")\n","\n","    def call(self, x):\n","        x = self.dense1(x)\n","        x = self.dense2(x)\n","\n","        return x\n","\n","\n","model = TestModel()\n","Y = model(X)\n","print(Y.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqIY88TMfy84","executionInfo":{"status":"ok","timestamp":1676622963021,"user_tz":-540,"elapsed":398,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"1ee2dcf9-5665-4786-d596-fc51d1562519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.51289296 0.4934756  0.59600556 0.5134553  0.44572946 0.5321825\n","  0.4027883  0.6747661  0.4576317  0.530953   0.596469   0.6055598\n","  0.48547143 0.41525283 0.6070244  0.4413876  0.34306937 0.4689866\n","  0.46478942 0.63999546]\n"," [0.51300675 0.49314854 0.59508735 0.5136718  0.44491655 0.5323915\n","  0.4031409  0.67500603 0.457251   0.53114533 0.5966938  0.60581285\n","  0.48560315 0.41476655 0.60716593 0.44151503 0.34344307 0.46923524\n","  0.46459854 0.64026475]\n"," [0.51307017 0.49314946 0.5952974  0.51352394 0.4450474  0.53245234\n","  0.40303054 0.6750563  0.45720947 0.5310178  0.59670126 0.6057058\n","  0.48577186 0.4148413  0.607012   0.44156954 0.3434744  0.46908563\n","  0.46450776 0.6404088 ]\n"," [0.51307946 0.49311775 0.595209   0.513544   0.44497025 0.53247356\n","  0.40306446 0.67507946 0.4571716  0.53103757 0.59672207 0.6057292\n","  0.48578578 0.41479546 0.6070248  0.44158074 0.3435103  0.46910876\n","  0.46448848 0.6404331 ]]\n"]}]},{"cell_type":"code","source":["## layers in models\n","## Model Implemetation - Use Sequential\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Dense(units=10, activation=\"sigmoid\"))\n","model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\"))\n","\n","Y = model(X)\n","# print(Y.numpy())\n","\n","print(type(model.layers)) ## <class 'list'> 즉, model 내 layer들이 리스트로 담겨있다.\n","print(model.layers)\n","print(model.layers[0].get_weights())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VRX97Ecg5sp","executionInfo":{"status":"ok","timestamp":1676623280465,"user_tz":-540,"elapsed":276,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"8ddd6e66-f37d-4e71-bd7d-ccc133a1c26e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","[<keras.layers.core.dense.Dense object at 0x7f78f337d100>, <keras.layers.core.dense.Dense object at 0x7f78f34c1bb0>]\n","[array([[ 5.0868767e-01,  4.6924931e-01, -3.5472062e-01,  1.3442928e-01,\n","        -2.0060053e-01, -5.3231871e-01,  5.1297432e-01, -4.5654881e-01,\n","        -4.1657746e-02, -3.3682179e-01],\n","       [ 1.5235919e-01,  1.7234355e-01,  1.9654232e-01, -5.9407949e-04,\n","         1.9443113e-01, -9.8697543e-03, -6.2415129e-01,  5.8389360e-01,\n","         2.6347220e-01, -2.7995890e-01],\n","       [-3.6243680e-01, -1.6605747e-01,  3.8324589e-01, -5.0648177e-01,\n","         4.5956701e-01, -3.8383499e-01, -2.8901938e-01,  2.5075376e-01,\n","         5.7464534e-01,  4.0833086e-01],\n","       [-5.3965068e-01,  1.9459593e-01,  6.9273591e-02,  5.2275807e-01,\n","        -4.8871666e-01, -5.1995116e-01, -5.5051506e-01, -2.6331148e-01,\n","        -2.5872084e-01,  2.1657151e-01],\n","       [-2.2188789e-01, -3.0434105e-01, -5.0316393e-01,  1.5037340e-01,\n","         4.4962591e-01,  9.6127927e-02,  2.6454204e-01, -1.7406738e-01,\n","         3.9467055e-01,  1.2832260e-01]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"]}]},{"cell_type":"code","source":["## Trainable Variables in models\n","## Model Implemetation - Use Sequential\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Dense(units=10, activation=\"sigmoid\"))\n","model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\"))\n","\n","Y = model(X)\n","# print(Y.numpy())\n","\n","print(type(model.trainable_variables))\n","print(len(model.trainable_variables))\n","\n","for train_variable in model.trainable_variables:\n","    print(train_variable.shape) ## model을 구성하는 Layer들이 가진 weight, bias들."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBX01W65h6Z4","executionInfo":{"status":"ok","timestamp":1676623421872,"user_tz":-540,"elapsed":260,"user":{"displayName":"김민준","userId":"08346406018640900317"}},"outputId":"84a2ad17-511e-4446-a89e-76ee39100a71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","4\n","(5, 10)\n","(10,)\n","(10, 20)\n","(20,)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ehS-ARNxiq36"},"execution_count":null,"outputs":[]}]}