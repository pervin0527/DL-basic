{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils as vutils\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/pervinco/Datasets/torch_mnist\"\n",
    "save_dir = \"./runs/cDCGAN\"\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "n_classes = 10\n",
    "image_size = 64\n",
    "x_dim = 1\n",
    "z_dim = 100\n",
    "d_dim = 64  # 판별자의 특성 맵 크기\n",
    "g_dim = 64  # 생성자의 특성 맵 크기\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# train_dataset = ImageFolder(root=data_dir, transform=transfomr)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cGAN + DCGAN\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_classes, z_dim, img_size, g_dim, x_dim):\n",
    "        super().__init__()\n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        input_dim = z_dim + n_classes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_dim, (g_dim * 8), 4, 1, 0, bias=False), ## (512, 4, 4)\n",
    "            nn.BatchNorm2d(g_dim * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d((g_dim * 8), (g_dim * 4), 4, 2, 1, bias=False), ## (256, 8, 8)\n",
    "            nn.BatchNorm2d(g_dim * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d((g_dim * 4), (g_dim * 2), 4, 2, 1, bias=False), ## (128, 16, 16)\n",
    "            nn.BatchNorm2d(g_dim * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d((g_dim * 2), g_dim, 4, 2, 1, bias=False), ## (64, 32, 32)\n",
    "            nn.BatchNorm2d(g_dim),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(img_size, x_dim, 4, 2, 1, bias=False), ## (1, 64, 64)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        labels = self.label_embedding(labels) ## [batch_size, n_classes]\n",
    "        labels = labels.unsqueeze(-1).unsqueeze(-1) ## [batch_size, n_classes, 1, 1]\n",
    "        # noise와 labels의 차원이 일치하도록 조정\n",
    "        x = torch.cat([noise, labels.expand(-1, -1, noise.size(2), noise.size(3))], 1)\n",
    "\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "G = Generator(n_classes=10, z_dim=100, img_size=64, g_dim=64, x_dim=1)\n",
    "z = torch.randn(1, z_dim, 1, 1)\n",
    "y = torch.randint(low=0, high=10, size=(1,), dtype=torch.int32)\n",
    "\n",
    "Gz = G(z, y)\n",
    "print(Gz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_classes, x_dim, d_dim):\n",
    "        super().__init__()\n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        input_dim = x_dim + n_classes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, d_dim, 4, 2, 1, bias=False), ## (64, 32, 32)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(d_dim, (d_dim * 2), 4, 2, 1, bias=False), ## (128, 16, 16)\n",
    "            nn.BatchNorm2d(d_dim * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d((d_dim * 2), (d_dim * 4), 4, 2, 1, bias=False), ## (256, 8, 8)\n",
    "            nn.BatchNorm2d(d_dim * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d((d_dim * 4), (d_dim * 8), 4, 2, 1, bias=False), ## (512, 4, 4)\n",
    "            nn.BatchNorm2d((d_dim * 8)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d((d_dim * 8), 1, 4, 1, 0, bias=False), ## (1, 1, 1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        labels = self.label_embedding(labels) ## [batch_size, n_classes]\n",
    "        labels = labels.unsqueeze(2).unsqueeze(3).expand(-1, -1, img.size(2), img.size(3))  # [batch_size, n_classes, height, width]\n",
    "        \n",
    "        img = torch.cat([img, labels], 1)\n",
    "        return self.model(img).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator(n_classes=10, x_dim=1, d_dim=64)\n",
    "x = torch.randn(1, 1, 64, 64)\n",
    "y = torch.randint(low=0, high=10, size=(1,), dtype=torch.int32)\n",
    "\n",
    "Dx = D(x, y)\n",
    "print(Dx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, dataloader, d_optimizer, g_optimizer, criterion, device):\n",
    "    D_losses, G_losses = [], []\n",
    "    D_real_accuracies, D_fake_accuracies_before_update, D_fake_accuracies_after_update = [], [], []\n",
    "    for idx, (images, labels) in enumerate(tqdm(dataloader, desc=\"Train\", leave=True)):\n",
    "        real_x = images.to(device)\n",
    "        real_y = labels.to(device)\n",
    "        bs = real_x.size(0)\n",
    "\n",
    "        real_labels = torch.ones(bs).to(device)\n",
    "        fake_labels = torch.zeros(bs).to(device)\n",
    "\n",
    "        D.zero_grad()\n",
    "        Gx = D(real_x, real_y).view(-1)  ## [128, 1, 1, 1] --> [128]\n",
    "        d_real_loss = criterion(Gx, real_labels)\n",
    "        d_real_loss.backward()\n",
    "        D_real_accuracies.append((Gx > 0.5).float().mean().item())\n",
    "\n",
    "        z = torch.randn(bs, z_dim, 1, 1, device=device) ## [batch_size, 100, 1, 1]\n",
    "        Gz = G(z, real_y) ## fake images [batch_size, 3, 64, 64]\n",
    "\n",
    "        DGz1 = D(Gz.detach(), real_y).view(-1) ## [128, 1, 1, 1] --> [128]\n",
    "        d_fake_loss = criterion(DGz1, fake_labels) \n",
    "        d_fake_loss.backward()\n",
    "        D_fake_accuracies_before_update.append((DGz1 < 0.5).float().mean().item())\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_optimizer.step()\n",
    "\n",
    "        G.zero_grad()\n",
    "        DGz2 = D(Gz, real_y).view(-1) ## [128, 1, 1, 1] --> [128]\n",
    "        g_loss = criterion(DGz2, real_labels)\n",
    "        g_loss.backward()\n",
    "        D_fake_accuracies_after_update.append((DGz2 > 0.5).float().mean().item())\n",
    "        g_optimizer.step()\n",
    "\n",
    "        D_losses.append(d_loss.item())\n",
    "        G_losses.append(g_loss.item())\n",
    "\n",
    "    avg_metrics = {\n",
    "        'D_loss': sum(D_losses) / len(D_losses),\n",
    "        'G_loss': sum(G_losses) / len(G_losses),\n",
    "        'D_real_acc': sum(D_real_accuracies) / len(D_real_accuracies),\n",
    "        'D_fake_acc_before': sum(D_fake_accuracies_before_update) / len(D_fake_accuracies_before_update),\n",
    "        'D_fake_acc_after': sum(D_fake_accuracies_after_update) / len(D_fake_accuracies_after_update),\n",
    "    }\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.0770\n",
      "Generator Loss: 1.9969\n",
      "Discriminator Real Accuracy: 0.7307\n",
      "Discriminator Fake Accuracy (Before G Update): 0.7453\n",
      "Discriminator Fake Accuracy (After G Update): 0.1240\n",
      "\n",
      "Epoch [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3191\n",
      "Generator Loss: 1.1071\n",
      "Discriminator Real Accuracy: 0.6041\n",
      "Discriminator Fake Accuracy (Before G Update): 0.6189\n",
      "Discriminator Fake Accuracy (After G Update): 0.2249\n",
      "\n",
      "Epoch [3/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3621\n",
      "Generator Loss: 0.9186\n",
      "Discriminator Real Accuracy: 0.5698\n",
      "Discriminator Fake Accuracy (Before G Update): 0.5799\n",
      "Discriminator Fake Accuracy (After G Update): 0.2554\n",
      "\n",
      "Epoch [4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3740\n",
      "Generator Loss: 0.8737\n",
      "Discriminator Real Accuracy: 0.5575\n",
      "Discriminator Fake Accuracy (Before G Update): 0.5633\n",
      "Discriminator Fake Accuracy (After G Update): 0.2706\n",
      "\n",
      "Epoch [5/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3724\n",
      "Generator Loss: 0.8504\n",
      "Discriminator Real Accuracy: 0.5584\n",
      "Discriminator Fake Accuracy (Before G Update): 0.5633\n",
      "Discriminator Fake Accuracy (After G Update): 0.2891\n",
      "\n",
      "Epoch [6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3688\n",
      "Generator Loss: 0.8556\n",
      "Discriminator Real Accuracy: 0.5605\n",
      "Discriminator Fake Accuracy (Before G Update): 0.5686\n",
      "Discriminator Fake Accuracy (After G Update): 0.2988\n",
      "\n",
      "Epoch [7/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:09<00:00, 47.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.3526\n",
      "Generator Loss: 0.9009\n",
      "Discriminator Real Accuracy: 0.5845\n",
      "Discriminator Fake Accuracy (Before G Update): 0.5857\n",
      "Discriminator Fake Accuracy (After G Update): 0.2749\n",
      "\n",
      "Epoch [8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:09<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.2923\n",
      "Generator Loss: 1.1142\n",
      "Discriminator Real Accuracy: 0.6307\n",
      "Discriminator Fake Accuracy (Before G Update): 0.6318\n",
      "Discriminator Fake Accuracy (After G Update): 0.2012\n",
      "\n",
      "Epoch [9/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.0238\n",
      "Generator Loss: 1.9405\n",
      "Discriminator Real Accuracy: 0.7519\n",
      "Discriminator Fake Accuracy (Before G Update): 0.7519\n",
      "Discriminator Fake Accuracy (After G Update): 0.0973\n",
      "\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.6935\n",
      "Generator Loss: 2.9187\n",
      "Discriminator Real Accuracy: 0.8496\n",
      "Discriminator Fake Accuracy (Before G Update): 0.8494\n",
      "Discriminator Fake Accuracy (After G Update): 0.0621\n",
      "\n",
      "Epoch [11/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.5078\n",
      "Generator Loss: 3.6397\n",
      "Discriminator Real Accuracy: 0.9030\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9084\n",
      "Discriminator Fake Accuracy (After G Update): 0.0494\n",
      "\n",
      "Epoch [12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.4637\n",
      "Generator Loss: 3.5809\n",
      "Discriminator Real Accuracy: 0.9155\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9202\n",
      "Discriminator Fake Accuracy (After G Update): 0.0528\n",
      "\n",
      "Epoch [13/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.4329\n",
      "Generator Loss: 3.8121\n",
      "Discriminator Real Accuracy: 0.9211\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9254\n",
      "Discriminator Fake Accuracy (After G Update): 0.0515\n",
      "\n",
      "Epoch [14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.3521\n",
      "Generator Loss: 4.0524\n",
      "Discriminator Real Accuracy: 0.9406\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9435\n",
      "Discriminator Fake Accuracy (After G Update): 0.0389\n",
      "\n",
      "Epoch [15/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.3661\n",
      "Generator Loss: 4.0900\n",
      "Discriminator Real Accuracy: 0.9379\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9423\n",
      "Discriminator Fake Accuracy (After G Update): 0.0405\n",
      "\n",
      "Epoch [16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.3948\n",
      "Generator Loss: 4.0604\n",
      "Discriminator Real Accuracy: 0.9329\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9358\n",
      "Discriminator Fake Accuracy (After G Update): 0.0469\n",
      "\n",
      "Epoch [17/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.3379\n",
      "Generator Loss: 4.1110\n",
      "Discriminator Real Accuracy: 0.9406\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9434\n",
      "Discriminator Fake Accuracy (After G Update): 0.0378\n",
      "\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 46.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.3793\n",
      "Generator Loss: 4.0923\n",
      "Discriminator Real Accuracy: 0.9321\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9360\n",
      "Discriminator Fake Accuracy (After G Update): 0.0442\n",
      "\n",
      "Epoch [19/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.4343\n",
      "Generator Loss: 3.8855\n",
      "Discriminator Real Accuracy: 0.9254\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9302\n",
      "Discriminator Fake Accuracy (After G Update): 0.0479\n",
      "\n",
      "Epoch [20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 468/468 [00:10<00:00, 45.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.4017\n",
      "Generator Loss: 4.0386\n",
      "Discriminator Real Accuracy: 0.9302\n",
      "Discriminator Fake Accuracy (Before G Update): 0.9331\n",
      "Discriminator Fake Accuracy (After G Update): 0.0465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def save_fake_images(epoch, G, fixed_noise, target_labels, save_dir, num_images=64):\n",
    "    with torch.no_grad():\n",
    "        # 각 클래스별로 이미지 생성\n",
    "        fake_images = G(fixed_noise, target_labels).detach().cpu()\n",
    "        \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Fake Images at Epoch {epoch}\")\n",
    "    \n",
    "    # 생성된 이미지를 그리드에 배치\n",
    "    grid = vutils.make_grid(fake_images, nrow=images_per_class, padding=2, normalize=True)\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    \n",
    "    plt.savefig(f\"{save_dir}/Epoch_{epoch}_Fake.png\")  # 이미지 파일로 저장\n",
    "    plt.close(fig)\n",
    "\n",
    "# ================================================================== #\n",
    "#                    Model, Optimizer, Cost func                     #\n",
    "# ================================================================== #\n",
    "G = Generator(n_classes, z_dim, image_size, g_dim).to(device)\n",
    "D = Discriminator(n_classes, x_dim, d_dim).to(device)\n",
    "D.apply(weights_init)\n",
    "G.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# ================================================================== #\n",
    "#                       Training Iterations                          #\n",
    "# ================================================================== #\n",
    "n_sample = 100\n",
    "images_per_class = n_sample // n_classes  # 각 클래스당 이미지 수\n",
    "fixed_noise = torch.randn(n_sample, z_dim, 1, 1, device=device)\n",
    "target_labels = torch.tensor([num for num in range(n_classes) for _ in range(images_per_class)]).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    metrics = train(D, G, train_dataloader, d_optimizer, g_optimizer, criterion, device)\n",
    "    print(f'Discriminator Loss: {metrics[\"D_loss\"]:.4f}')\n",
    "    print(f'Generator Loss: {metrics[\"G_loss\"]:.4f}')\n",
    "    print(f'Discriminator Real Accuracy: {metrics[\"D_real_acc\"]:.4f}')\n",
    "    print(f'Discriminator Fake Accuracy (Before G Update): {metrics[\"D_fake_acc_before\"]:.4f}')\n",
    "    print(f'Discriminator Fake Accuracy (After G Update): {metrics[\"D_fake_acc_after\"]:.4f}\\n') ##  판별자가 가짜 이미지를 \"진짜\"로 잘못 분류한 점수.\n",
    "\n",
    "    save_fake_images(epoch+1, G, fixed_noise, target_labels, save_dir, num_images=n_sample)\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), f'{save_dir}/G.ckpt')\n",
    "torch.save(D.state_dict(), f'{save_dir}/D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
